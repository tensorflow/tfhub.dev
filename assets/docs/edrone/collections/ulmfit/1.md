# Collection edrone/ulmfit/1

Collection of ULMFiT encoders trained on the Wikipedia dataset.

<!-- dataset: wikipedia -->
<!-- task: text-embedding -->
<!-- network-architecture: ulmfit -->

## Overview

This collection contains ULMFiT recurrent language models trained on Wikipedia dumps for English and Polish.

The models themselves were trained using [FastAI](https://fast.ai/) and then exported to a TensorFlow-usable format. The encoders can now be used just like any other Keras objects. In our repo at https://bitbucket.org/edroneteam/tf2_ulmfit/src/master/ we also provide python code used to train and convert the models and links to Sentencepiece vocabularies needed for numericalization. See the descriptions below.



## Models

| Name | Language | Vocabulary size | Cased |
|------|-------------|--------------|----------|
| [en_sp35k_cased](https://tfhub.dev/edrone/ulmfit/en/sp35k_cased/1) | English | 35k |   cased   |
| [en_sp35k_uncased](https://tfhub.dev/edrone/ulmfit/en/sp35k_uncased/1) | English | 35k | uncased |
| [pl_sp35k_cased](https://tfhub.dev/edrone/ulmfit/pl/sp35k_cased/1) | Polish | 35k |   cased   |
| [pl_sp50k_cased](https://tfhub.dev/edrone/ulmfit/pl/sp50k_cased/1) | Polish | 50k | cased |
| [pl_sp50k_uncased](https://tfhub.dev/edrone/ulmfit/pl/sp50k_uncased/1) | Polish | 50k |   uncased   |



# Module google/magenta/arbitrary-image-stylization-v1-256/2

Fast arbitrary image style transfer.

<!-- dataset: multiple -->
<!-- asset-path: legacy -->
<!-- module-type: image-style-transfer -->
<!-- network-architecture: other -->
<!-- fine-tunable: false -->
<!-- format: hub -->


[![Open Colab notebook]](https://colab.research.google.com/github/tensorflow/hub/blob/master/examples/colab/tf2_arbitrary_image_stylization.ipynb)

## Overview

The original work for artistic style transfer with neural networks proposed a
slow optimization algorithm that works on any arbitrary painting. Subsequent
work developed a method for fast artistic style transfer that may operate in
real time, but was limited to one or a limited set of styles.

This module performs fast artistic style transfer that may work on arbitrary
painting styles as described in [1].

#### Example use

```python
# Load content and style images (see example in the attached colab).
content_image = plt.imread(content_image_path)
style_image = plt.imread(style_image_path)
# Convert to float32 numpy array, add batch dimension, and normalize to range [0, 1]. Example using numpy:
content_image = content_image.astype(np.float32)[np.newaxis, ...] / 255.
style_image = style_image.astype(np.float32)[np.newaxis, ...] / 255.
# Optionally resize the images. It is recommended that the style image is about
# 256 pixels (this size was used when training the style transfer network).
# The content image can be any size.
style_image = tf.image.resize(style_image, (256, 256))

# Load image stylization module.
hub_module = hub.load('https://tfhub.dev/google/magenta/arbitrary-image-stylization-v1-256/2')

# Stylize image.
outputs = hub_module(tf.constant(content_image), tf.constant(style_image))
stylized_image = outputs[0]
```

## References

[1] Golnaz Ghiasi, Honglak Lee, Manjunath Kudlur, Vincent Dumoulin, Jonathon
Shlens. [Exploring the structure of a real-time, arbitrary neural artistic
stylization network](https://arxiv.org/abs/1705.06830). Proceedings of the
British Machine Vision Conference (BMVC), 2017.

# Collection sayakpaul/convnext/1

Collection of ConvNeXt models.

<!-- dataset: imagenet-ilsvrc-2012-cls -->
<!-- task: image-classification -->

## Overview

This collection contains different ConvNeXt [1] models. For more details on the training protocols,
please follow [2]. The original model weights are provided from [2]. There were ported to Keras models
(`tf.keras.Model`) and then serialized as TensorFlow SavedModels. The porting steps are available in [3].
Some models in this collection were first pre-trained on ImageNet-21k and then fine-tuned on ImageNet-1k.
Rest were directly pre-trained on ImageNet-1k. The former usually leads to better performance.

## About the models

Models included in this collection have two variants: (1) off-the-shelf inference for image
classification, (2) fine-tuning on downstream tasks. These models are accompanied by
Colab Notebooks for demonstration purposes. 

The table below provides a performance summary:

| name | original acc@1 | keras acc@1 |
|:---:|:---:|:---:|
| convnext_tiny_1k_224 | 82.1 | 81.312 |
| convnext_small_1k_224 | 83.1 | 82.392 |
| convnext_base_1k_224 | 83.8 | 83.28 |
| convnext_base_1k_384 | 85.1 | 84.876 |
| convnext_large_1k_224 | 84.3 | 83.844 |
| convnext_large_1k_384 | 85.5 | 85.376 |
|  |  |  |
| convnext_base_21k_1k_224 | 85.8 | 85.364 |
| convnext_base_21k_1k_384 | 86.8 | 86.79 |
| convnext_large_21k_1k_224 | 86.6 | 86.36 |
| convnext_large_21k_1k_384 | 87.5 | 87.504 |
| convnext_xlarge_21k_1k_224 | 87.0 | 86.732 |
| convnext_xlarge_21k_1k_384 | 87.8 | 87.68 |

Note that the top-1 accuracy is reported on the ImageNet-1k validation set. [This notebook](https://github.com/sayakpaul/ConvNeXt-TF/blob/main/i1k_eval/eval.ipynb) was used to get `keras acc@1` scores.

### Image classifiers

* [convnext_tiny_1k_224](https://tfhub.dev/sayakpaul/convnext_tiny_1k_224/1)
* [convnext_small_1k_224](https://tfhub.dev/sayakpaul/convnext_small_1k_224/1)
* [convnext_base_1k_224](https://tfhub.dev/sayakpaul/convnext_base_1k_224/1)
* [convnext_base_1k_384](https://tfhub.dev/sayakpaul/convnext_base_1k_384/1)
* [convnext_large_1k_224](https://tfhub.dev/sayakpaul/convnext_large_1k_224/1)
* [convnext_large_1k_384](https://tfhub.dev/sayakpaul/convnext_large_1k_384/1)
* [convnext_base_21k_1k_224](https://tfhub.dev/sayakpaul/convnext_base_21k_1k_224/1)
* [convnext_base_21k_1k_384](https://tfhub.dev/sayakpaul/convnext_base_21k_1k_384/1)
* [convnext_large_21k_1k_224](https://tfhub.dev/sayakpaul/convnext_large_21k_1k_224/1)
* [convnext_large_21k_1k_384](https://tfhub.dev/sayakpaul/convnext_large_21k_1k_384/1)
* [convnext_xlarge_21k_1k_224](https://tfhub.dev/sayakpaul/convnext_xlarge_21k_1k_224/1)
* [convnext_xlarge_21k_1k_384](https://tfhub.dev/sayakpaul/convnext_xlarge_21k_1k_384/1)
* [convnext_base_21k_224](https://tfhub.dev/sayakpaul/convnext_base_21k_224/1)
* [convnext_large_21k_224](https://tfhub.dev/sayakpaul/convnext_large_21k_224/1)
* [convnext_xlarge_21k_224](https://tfhub.dev/sayakpaul/convnext_xlarge_21k_224/1)


### Feature extractors

* [convnext_tiny_1k_224_fe](https://tfhub.dev/sayakpaul/convnext_tiny_1k_224_fe/1)
* [convnext_small_1k_224_fe](https://tfhub.dev/sayakpaul/convnext_small_1k_224_fe/1)
* [convnext_base_1k_224_fe]((https://tfhub.dev/sayakpaul/convnext_base_1k_224_fe/1))
* [convnext_base_1k_384_fe](https://tfhub.dev/sayakpaul/convnext_base_1k_384_fe/1)
* [convnext_large_1k_224_fe](https://tfhub.dev/sayakpaul/convnext_large_1k_224_fe/1)
* [convnext_large_1k_384_fe](https://tfhub.dev/sayakpaul/convnext_large_1k_384_fe/1)
* [convnext_base_21k_1k_224_fe](https://tfhub.dev/sayakpaul/convnext_base_21k_1k_224_fe/1)
* [convnext_base_21k_1k_384_fe](https://tfhub.dev/sayakpaul/convnext_base_21k_1k_384_fe/1)
* [convnext_large_21k_1k_224_fe](https://tfhub.dev/sayakpaul/convnext_large_21k_1k_224_fe/1)
* [convnext_large_21k_1k_384_fe](https://tfhub.dev/sayakpaul/convnext_large_21k_1k_384_fe/1)
* [convnext_xlarge_21k_1k_224_fe](https://tfhub.dev/sayakpaul/convnext_xlarge_21k_1k_224_fe/1)
* [convnext_xlarge_21k_1k_384_fe](https://tfhub.dev/sayakpaul/convnext_xlarge_21k_1k_384_fe/1)
* [convnext_base_21k_224_fe](https://tfhub.dev/sayakpaul/convnext_base_21k_224_fe/1)
* [convnext_large_21k_224_fe](https://tfhub.dev/sayakpaul/convnext_large_21k_224_fe/1)
* [convnext_xlarge_21k_224_fe](https://tfhub.dev/sayakpaul/convnext_xlarge_21k_224_fe/1)


## References

[1] [A ConvNet for the 2020s by Liu et al.](https://arxiv.org/abs/2201.03545)
[2] [ConvNeXt GitHub](https://github.com/facebookresearch/ConvNeXt)
[3] [ConvNeXt-TF GitHub](https://github.com/sayakpaul/ConvNeXt-TF)

## Acknowledgements

* [Vasudev Gupta](https://github.com/vasudevgupta7) 
* [Luiz Gustavo Martins](https://twitter.com/gusthema)
* [Willi Gierke](https://ch.linkedin.com/in/willi-gierke)
* [ML-GDE program](https://developers.google.com/programs/experts/)
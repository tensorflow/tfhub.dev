# Module tensorflow/mask_rcnn/inception_resnet_v2_1024x1024/1

Mask R-CNN Object detection model,trained on COCO 2017 dataset.

<!-- asset-path: internal -->
<!-- module-type: image-object-detection -->
<!-- fine-tunable: false -->
<!-- format: saved_model_2 -->
<!-- network-architecture: mask-r-cnn -->
<!-- dataset: coco-2017 -->

[![Open Colab notebook]](https://colab.research.google.com/github/tensorflow/hub/blob/master/examples/colab/tf2_object_detection.ipynb)

## Overview

Mask R-CNN with Inception Resnet v2 (using regular Convolutions instead of
Dilated ones). Trained on [COCO 2017](https://cocodataset.org/) dataset
(Synchronous SGD across 8 GPUs) with batch size 16 (trained on images of
1024x1024 resolution).

Initialized from Imagenet classification checkpoint.

Model created using the
[TensorFlow Object Detection API](https://github.com/tensorflow/models/tree/master/research/object_detection)

An example detection result is shown below.

![Object detector output](https://www.gstatic.com/aihub/tfhub/detection/od_no_keypoints.png)

#### Example use

```
# Apply image detector on a single image.
detector = hub.load("https://tfhub.dev/tensorflow/mask_rcnn/inception_resnet_v2_1024x1024/1")
detector_output = detector(image_tensor)
class_ids = detector_output["detection_classes"]
```

### Inputs

A three-channel image of variable size - the model does **NOT** support
batching. The input tensor is a `tf.uint8` tensor with shape `[1, height, width,
3]` with values in `[0, 255]`.

### Outputs

The output dictionary contains:

*   `num_detections`: a `tf.int` tensor with only one value, the number of
    detections `[N]`.
*   `detection_boxes`: a `tf.float32` tensor of shape `[N, 4]` containing
    bounding box coordinates in the following order: `[ymin, xmin, ymax, xmax]`.
*   `detection_classes`: a `tf.int` tensor of shape `[N]` containing detection
    class index from the label file.
*   `detection_scores`: a `tf.float32` tensor of shape `[N]` containing
    detection scores.
*   `raw_detection_boxes`: a `tf.float32` tensor of shape `[1, M, 4]` containing
    decoded detection boxes without Non-Max suppression. `M` is the number of
    raw detections.
*   `raw_detection_scores`: a `tf.float32` tensor of shape `[1, M, 90]` and
    contains class score logits for raw detection boxes. `M` is the number of
    raw detections.
*   `detection_anchor_indices`: a `tf.float32` tensor of shape `[N]` and
    contains the anchor indices of the detections after NMS.
*   `detection_multiclass_scores`: a `tf.float32` tensor of shape `[1, N, 90]`
    and contains class score distribution (including background) for detection
    boxes in the image including background class.
*   `refined_box_encodings`: a 3-D tensor with shape [total_num_proposals,
    num_classes, code_size] representing predicted (final) refined box
    encodings, where total_num_proposals=batch_size * max_num_proposals. If
    using a shared box across classes the shape will instead be
    [total_num_proposals, 1, self._box_coder.code_size].
*   `mask_predictions`: a 4-D tensor with shape [batch_size, max_detection,
    mask_height, mask_width] containing instance mask predictions.
*   `final_anchors`: a 3-D float tensor of shape [batch_size, max_num_proposals,
    4] containing the reference anchors for raw detection boxes in normalized
    coordinates.
*   `rpn_box_predictor_features`: A 4-D `tf.float32` tensor with shape
    [batch_size, height, width, depth] to be used for predicting proposal boxes
    and corresponding objectness scores.
*   `class_predictions_with_background`: a 3-D tensor with shape
    [total_num_proposals, num_classes + 1] containing class predictions (logits)
    for each of the anchors, where total_num_proposals=batch_size *
    max_num_proposals. Note that this tensor *includes* background class
    predictions (at class index 0).
*   `raw_detection_boxes`: a 4-D `tf.float32` tensor with shape [batch_size,
    max_num_proposals, num_classes, 4] in normalized coordinates.
*   `proposal_boxes`: A `tf.float32` tensor of shape [batch_size,
    max_num_proposals, 4] representing decoded proposal bounding boxes in
    absolute coordinates.
*   `rpn_box_encodings`: 3-D float tensor of shape [batch_size, num_anchors,
    code_size] containing predicted boxes.
*   `box_classifier_features`: a 4-D `tf.float32` tensor representing the
    features for each proposal.
*   `proposal_boxes_normalized`: A `tf.float32` tensor of shape [batch_size,
    max_num_proposals, 4] representing decoded proposal bounding boxes in
    normalized coordinates. Can be used to override the boxes proposed by the
    RPN, thus enabling one to extract features and get box classification and
    prediction for externally selected areas of the image.
*   `num_proposals`: An int32 tensor of shape [batch_size] representing the
    number of proposals generated by the RPN. `num_proposals` allows us to keep
    track of which entries are to be treated as zero paddings and which are not
    since we always pad the number of proposals to be `max_num_proposals` for
    each image.
*   `anchors`: A 2-D tensor of shape [num_anchors, 4] representing anchors for
    the first stage RPN (in absolute coordinates). Note that `num_anchors` can
    differ depending on whether the model is created in training or inference
    mode.
*   `image_shape`: a 1-D tensor of shape [4] representing the input image shape.
*   `rpn_objectness_predictions_with_background`: 3-D float tensor of shape
    [batch_size, num_anchors, 2] containing class predictions (logits) for each
    of the anchors. Note that this tensor *includes* background class
    predictions (at class index 0).
*   `detection_masks`: [batch, max_detections, mask_height, mask_width]. Note
    that a pixel-wise sigmoid score converter is applied to the detection masks.
*   `rpn_features_to_crop`: A 4-D `tf.float32` tensor with shape [batch_size,
    height, width, depth] representing image features to crop using the proposal
    boxes predicted by the RPN.
*   `detection_anchor_indices`: [batch, max_detections] with anchor indices.

### Suitable use cases

This model is **suitable** for localizing the most prominent objects in an
image.

### Unsuitable use cases

This model is **unsuitable** for standalone use in mission-critical applications
such as obstacle and human detection for autonomous driving.

#### Source

The model's checkpoints are
[publicly available](https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/tf2_detection_zoo.md)
as a part of the
[TensorFlow Object Detection API](https://github.com/tensorflow/models/tree/master/research/object_detection).

#### Metrics

Metric                    | Value     | Outputs
------------------------- | --------- | ---------------
mAP on COCO 2017 test set | 39.0/34.6 | Boxes/Keypoints

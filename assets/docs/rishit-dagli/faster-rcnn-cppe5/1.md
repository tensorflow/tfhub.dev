# Module rishit-dagli/faster-rcnn-cppe5/1

The Faster RCNN model (with ResNet 101 backbone) trained on the CPPE - 5 (Medical Personal Protective Equipment) dataset [1].

<!-- task: image-object-detection -->
<!-- network-architecture: faster-r-cnn -->
<!-- dataset: cppe-5 -->
<!-- fine-tunable: false -->
<!-- license: apache-2.0 -->
<!-- format: saved_model_2 -->
<!-- asset-path: https://storage.googleapis.com/cppe-5/trained_models/faster_rcnn/faster_rcnn.tar.gz -->

### TF2 SavedModel
This is a [SavedModel in TensorFlow 2 format](https://www.tensorflow.org/hub/tf2_saved_model). Using it requires TensorFlow 2 (or 1.15) and TensorFlow Hub 0.5.0 or newer.

### Overview
The Faster RCNN model was proposed by Ren et al. in the paper "Faster R-CNN: Towards Real-Time Object Detection with Region Proposal Networks" [2]. The Faster RCNN models is trained on the CPPE - 5 dataset we present in our paper "CPPE - 5: Medical Personal Protective Equipment Dataset" [1] which is a new challenging dataset with an aim to facilitate the study of subordinate categorization of medical personal protective equipments. This dataset mostly contains non-iconic images or non-canonical perspectives in their natural context. This allows models to be better at generalizing, being easily deployable to real-world scenarios and often contain other objects in an image as well.

We include the training code as well some tools for this model in our paper GitHub repository [3].

Note: In no case should this model be used to engage in any kind of high-risk activities, please [TF Hub Additional Terms of Service](https://tfhub.dev/terms#hra) for more information.

### Model Performance
Here we present the performance of the Faster RCNN model on the CPPE - 5 dataset. For evaluation, we adopt the metrics from the COCO detection evaluation criteria, including the mean Average Precision (AP) across IoU thresholds ranging from 0.50 to 0.95 at different scales.

|   Method    | AP<sup>box</sup> | AP<sub>50</sub><sup>box</sup> | AP<sub>75</sub><sup>box</sup> | AP<sub>S</sub><sup>box</sup> | AP<sub>M</sub><sup>box</sup> | AP<sub>L</sub><sup>box</sup> |
| :---------: | :--------------: | :---------------------------: | :---------------------------: | :--------------------------: | :--------------------------: | :--------------------------: |
| Faster RCNN |       44.0       |              73.8             |              47.8             |             30.0             |             34.7             |             52.5             |

### Usage
The saved model can be loaded directly:

```py
import tensorflow_hub as hub

model = hub.load("https://tfhub.dev/rishit-dagli/faster-rcnn-cppe5/1")
```

The inputs to the models should:

- have color values in the range `[0,1]`, following the [common image input](https://www.tensorflow.org/hub/common_signatures/images#input) conventions
- the expected size of the input images is height x width = 800 x 1216 pixels
- the images should in the `channels_first` format
- The shape of the input tensor would ths be `(1, 3, 800, 1216)`, the first dimension represents the batch size

The model outputs are:

- `outputs['dets']`: A tensor of shape `[batch_size, 100, 5]` with the bounding boxes in normalized coordinates.
- `outputs['labels']`: A tensor of shape `[batch_size, 100]` with the class labels for the bounding boxes.

It can also be used within a KerasLayer:

```py
hub_layer = hub.KerasLayer("https://tfhub.dev/rishit-dagli/faster-rcnn-cppe5/1")
```

### Model Complexity
We measure the model complexity in terms of the number of parameters FLOPS and FPS. The inference speed FPS (Frames per second) for detector is measured on a machine with 1 Tesla V100 GPU.

|          Method           |      AP<sup>box</sup>      | #Params  |   FLOPs   | FPS  |
|:-------------------------:|:--------------------------:|:--------:|:---------:|:----:|
|        Faster RCNN        |            44.0            | 60.14 M  | 282.75 G  | 15.6 |

### Acknowledgements

This is joint work with Ali Mustufa Shaikh. The authors would like to thank Google for supporting this work by providing Google Cloud credits. The authors would also like to thank [Google TPU Research Cloud (TRC) program](https://sites.research.google/trc) for providing access to TPUs.

### References

[1] Dagli, Rishit, and Ali Mustufa Shaikh. ‘CPPE-5: Medical Personal Protective Equipment Dataset’. ArXiv:2112.09569 [Cs], Dec. 2021. arXiv.org, http://arxiv.org/abs/2112.09569.

[2] Ren, Shaoqing et al. “Faster R-CNN: Towards Real-Time Object Detection with Region Proposal Networks”. IEEE Transactions on Pattern Analysis and Machine Intelligence 39.6 (2017): 1137–1149. Web.

[3] https://github.com/Rishit-dagli/CPPE-Dataset
# Module google/&zwnj;inaturalist/&zwnj;inception_v3/&zwnj;feature_vector/3
Feature vectors of images with Inception V3 trained on the iNaturalist (iNat) 2017 dataset.

<!-- dataset: iNaturalist (iNat) 2017 -->
<!-- asset-path: legacy -->
<!-- fine-tunable: true -->
<!-- format: hub -->
<!-- module-type: image-feature-vector -->
<!-- network-architecture: Inception V3 -->


## hub.Module for TF1

This is a hub.Module for use with TensorFlow 1.

## Overview

This module uses the Inception V3 architecture, trained on the iNaturalist
dataset of plants and animals.

### Architecture

Inception V3 is a neural network architecture for image classification,
originally published by

  * Christian Szegedy, Vincent Vanhoucke, Sergey Ioffe, Jonathon Shlens,
    Zbigniew Wojna: ["Rethinking the Inception Architecture for Computer
    Vision"](https://arxiv.org/abs/1512.00567), 2015.

This TF-Hub module uses the TF-Slim implementation of `inception_v3`.
The module contains a trained instance of the network, packaged to get
[feature vectors from images](https://www.tensorflow.org/hub/common_signatures/images.md#feature-vector).
The classification layer has been omitted.


### Training

The weights for this module were obtained by training on the iNaturalist
(iNat) 2017 dataset, after pre-training on ILSVRC-2012-CLS ("Imagenet").

The iNat2017 dataset consists of 579,184 training images and 95,986 validation
images from 5,089 species, taken from
[www.inaturalist.org](http://www.inaturalist.org).
Images were collected with different camera types, have varying image quality,
feature a large class imbalance, and have been verified by multiple
citizen scientists. The iNat2017 dataset was originally described in

  * Grant Van Horn, Oisin Mac Aodha, Yang Song, Yin Cui, Chen Sun,
    Alex Shepard, Hartwig Adam, Pietro Perona, Serge Belongie:
    ["The iNaturalist Species Classification and Detection
    Dataset"](https://arxiv.org/abs/1707.06642), CVPR 2018.

This model was trained for the study reported in

  * Yin Cui, Yang Song, Chen Sun, Andrew Howard, Serge Belongie:
    ["Large Scale Fine-Grained Categorization and Domain-Specific Transfer
    Learning"](https://arxiv.org/abs/1806.06193), CVPR 2018.

Training was done on a Cloud TPU, with "Inception-style" data
augmentation and preprocessing as for Imagenet, using the RMSProp optimizer
with epsilon = 1.0, momentum of 0.9, and a batch size of 32.
The network was trained from a checkpoint pretrained on ILSVRC-2012-CLS
("Imagenet"). The initial learning rate was set to 0.0045, with exponential
decay of 0.94 after every 4 epochs.


## Usage

This module implements the common signature for computing
[image feature vectors](https://www.tensorflow.org/hub/common_signatures/images#feature-vector).
It can be used with the `hub.Module` API like

```python
module = hub.Module("https://tfhub.dev/google/inaturalist/inception_v3/feature_vector/3")
height, width = hub.get_expected_image_size(module)
images = ...  # A batch of images with shape [batch_size, height, width, 3].
features = module(images)  # Features with shape [batch_size, num_features].
```

...or using the signature name `image_feature_vector`.
For use with TF2 APIs, see TF Hub's [migration
guide](https://github.com/tensorflow/hub/blob/master/docs/migration_tf2.md).

The output for each image
in the batch is a feature vector of size `num_features` = 2048.

The input `images` are expected to have color values in the range [0,1],
following the
[common image input](https://www.tensorflow.org/hub/common_signatures/images#input)
conventions.
The expected size of the input images is
`height` x `width` = 299 x 299 pixels
by default, but other input sizes are possible (within limits).


## Fine-tuning

Consumers of this module can [fine-tune](https://www.tensorflow.org/hub/tf1_hub_module#fine-tuning) it.
This requires importing the graph version with tag set `{"train"}`
in order to operate batch normalization in training mode, and setting
`trainable=True`.

The momentum (a.k.a. decay coefficient) of batch norm's exponential moving
averages defaults to 0.99 for this module, in order to accelerate training
on small datasets (or with huge batch sizes).
Advanced users can set another value (say, 0.997) by calling this module like

```python
module = hub.Module("https://tfhub.dev/google/inaturalist/inception_v3/feature_vector/3",
                    trainable=True, tags={"train"})
features = module(inputs=dict(images=images, batch_norm_momentum=0.997),
                  signature="image_feature_vector_with_bn_hparams")
```


## Changelog

#### Version 1

  * Initial release.

#### Version 3

  * Support for variable input size.
  * Fine-tuning: change default batch norm momentum to 0.99 and
    make it configurable.
  * Requires PIP package `tensorflow-hub>=0.2.0`.

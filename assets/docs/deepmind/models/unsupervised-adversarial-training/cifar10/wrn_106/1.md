# Module deepmind/unsupervised-adversarial-training/cifar10/wrn_106/1

UAT++ adversarially trained WRN-106 (wide residual network) model using 80m@200K
unlabeled data and CIFAR-10.

<!-- dataset: cifar-10 -->
<!-- asset-path: legacy -->
<!-- module-type: image-classification -->
<!-- network-architecture: WRN-106 -->
<!-- fine-tunable: false -->
<!-- format: hub -->


## Overview

This is WRN-106 model trained with the UAT++ algorithm using 80m@200K unlabeled
data and CIFAR-10 [1].

#### Example use

Please refer to the full examples in the
[github repository](https://github.com/deepmind/deepmind-research/tree/master/unsupervised_adversarial_training).

```python
# Load dataset
_, data_test = tf.keras.datasets.cifar10.load_data()
data = _build_dataset(data_test, batch_size=batch_size, shuffle=False)

def _cifar_meanstd_normalize(image):
  # Channel-wise means and std devs calculated from the CIFAR-10 training set
  cifar_means = [125.3, 123.0, 113.9]
  cifar_devs = [63.0, 62.1, 66.7]
  rescaled_means = [x / 255. for x in cifar_means]
  rescaled_devs = [x / 255. for x in cifar_devs]
  image = (image - rescaled_means) / rescaled_devs
  return image

Sample = collections.namedtuple('Sample', ['image', 'label'])
def _build_dataset(raw_data, batch_size=32, shuffle=False):
  images, labels = raw_data
  labels = np.squeeze(labels)
  samples = Sample(images.astype(np.float32) / 255., labels.astype(np.int64))
  data = tf.data.Dataset.from_tensor_slices(samples)
  if shuffle:
    data = data.shuffle(1000)
  return data.repeat().batch(batch_size).make_one_shot_iterator().get_next()

# Load UAT module.
UAT_HUB_URL = ('https://tfhub.dev/deepmind/unsupervised-adversarial-training/'
               'cifar10/wrn_106/1')
def make_classifier():
  model = hub.Module(UAT_HUB_URL)
  def classifier(x):
    x = _cifar_meanstd_normalize(x)
    model_input = dict(x=x, decay_rate=0.1, prefix='default')
    return model(model_input)
  return classifier

# Note that a `classifier` is a function mapping [0,1]-scaled image Tensors
# to a logit Tensor. In particular, it includes *both* the preprocessing
# function, and the neural network.
classifier = make_classifier()

# Inference
logits = classifier(data.image)
```

## References

[1] Jonathan Uesato*, Jean-Baptiste Alayrac*, Po-Sen Huang*, Robert Stanforth,
Alhussein Fawzi, Pushmeet Kohli.
[Are Labels Required for Improving Adversarial Robustness?](https://arxiv.org/abs/1905.13725).
*NeurIPS*, 2019. (* denotes equal contribution)

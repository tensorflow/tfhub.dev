# Module google/&zwnj;imagenet/&zwnj;nasnet_large/&zwnj;feature_vector/1
Feature vectors of images with NASNet-A (large) trained on ImageNet (ILSVRC-2012-CLS).

<!-- dataset: ImageNet (ILSVRC-2012-CLS) -->
<!-- asset-path: legacy -->
<!-- module-type: image-feature-vector -->
<!-- network-architecture: NASNet-A (large) -->
<!-- fine-tunable: true -->
<!-- format: hub -->


## Overview

NASNet-A is a family of convolutional neural networks for image classification.
The architecture of its convolutional cells (or layers) has been found by
Neural Architecture Search (NAS). NAS and NASNet were originally published by

  * Barret Zoph, Quoc V. Le: ["Neural Architecture Search
    with Reinforcement Learning"](https://arxiv.org/abs/1611.01578), 2017.
  * Barret Zoph, Vijay Vasudevan, Jonathon Shlens, Quoc V. Le:
    ["Learning Transferable Architectures for Scalable Image
    Recognition"](https://arxiv.org/abs/1707.07012), 2017.

NASNets come in various sizes. This TF-Hub module uses the TF-Slim
implementation `nasnet_large` of NASNet-A for ImageNet
that uses 18 Normal Cells, starting with
168 convolutional filters (after the "ImageNet stem").
It has an input size of 331x331 pixels.

The module contains a trained instance of the network, packaged to get
[feature vectors from images](https://www.tensorflow.org/hub/common_signatures/images#feature-vector).
If you want the full model including the classification it was originally
trained for, use module
[`google/imagenet/nasnet_large/classification/1`](https://tfhub.dev/google/imagenet/nasnet_large/classification/1)
instead.


## Training

The checkpoint exported into this module was `nasnet-a_large_04_10_2017/model.ckpt` downloaded
from
[NASNet's pre-trained models](https://github.com/tensorflow/models/blob/master/research/slim/nets/nasnet/README.md).
Its weights were originally obtained by training on the ILSVRC-2012-CLS
dataset for image classification ("ImageNet").

## Usage

This module implements the common signature for computing
[image feature vectors](https://www.tensorflow.org/hub/common_signatures/images#feature-vector).
It can be used like

```python
module = hub.Module("https://tfhub.dev/google/imagenet/nasnet_large/feature_vector/1")
height, width = hub.get_expected_image_size(module)
images = ...  # A batch of images with shape [batch_size, height, width, 3].
features = module(images)  # Features with shape [batch_size, num_features].
```

...or using the signature name `image_feature_vector`. The output for each image
in the batch is a feature vector of size `num_features` = 4032.

For this module, the size of the input image is fixed to
`height` x `width` = 331 x 331 pixels.
The input `images` are expected to have color values in the range [0,1],
following the
[common image input](https://www.tensorflow.org/hub/common_signatures/images#input)
conventions.


## Fine-tuning

Consumers of this module can [fine-tune](https://www.tensorflow.org/hub/tf1_hub_module#fine-tuning) it.

Fine-tuning requires to import the graph version with tag set `{"train"}`
in order to operate batch normalization and dropout in training mode.
The dropout probability in NASNet path dropout is not scaled with
the training steps of fine-tuning and remains at the final (maximal) value
from the initial training.


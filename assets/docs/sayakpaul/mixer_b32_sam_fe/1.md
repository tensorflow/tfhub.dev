# Module sayakpaul/mixer_b32_sam_fe/1

MLP-Mixer B-32 feature extractor fine-tuned on ImageNet-1k.

<!-- asset-path: https://storage.googleapis.com/flowers-experimental/mixer/B_32_sam_fe.tar.gz -->
<!-- task: image-classification -->
<!-- network-architecture: mixer -->
<!-- format: saved_model_2 -->
<!-- fine-tunable: true -->
<!-- license: apache-2.0 -->
<!-- colab: https://colab.research.google.com/github/sayakpaul/MLPMixer-jax2tf/blob/main/fine-tune.ipynb -->


## Overview

This model is an MLP-Mixer of type B-32 [1] pre-trained on the ImageNet-1k dataset [2]. Training recipes are available
in [3]. This model is suitable for fine-tuning. Other models can be found from the [collection page](https://tfhub.dev/sayakpaul/collections/mlp-mixer/1).

## Using this model

```python
model = tf.keras.Sequential([
    layers.InputLayer((224, 224, 3)),
    hub.KerasLayer("https://tfhub.dev/sayakpaul/mixer_b32_sam_fe/1", trainable=True),
    layers.Dense(num_classes, activation="softmax")
])
...
```

Inputs to the model must:

1. be four dimensional Tensors of the shape `(batch_size, height, width, num_channels)`. Note that the model expects
   images with  `channels_last`  property. `num_channels` must be 3. 
2. be resized to 224x224 resolution.
3. have pixel values in the range `[-1, 1]`.


## Notes

The original model weights are provided as a `.npz` file [4]. There were ported to a TensorFlow SavedModel. The porting
steps are available in [5].

## References

[1] [MLP-Mixer: An all-MLP Architecture for Vision by Tolstikhin et al.](https://arxiv.org/abs/2105.01601)

[2] [ImageNet-1k](https://www.image-net.org/challenges/LSVRC/2012/index.php)  

[3] [When Vision Transformers Outperform ResNets without Pretraining or Strong Data Augmentations by Chen et al.](https://arxiv.org/abs/2106.01548)

[4] [Vision Transformer GitHub](https://github.com/google-research/vision_transformer)

[5] [Colab Notebook for assembling Mixer models in TensorFlow](https://colab.research.google.com/github/sayakpaul/MLPMixer-jax2tf/blob/main/conversion.ipynb)
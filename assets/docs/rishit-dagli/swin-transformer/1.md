# Module rishit-dagli/swin-transformer/1

Swin Transformer model, a general purpose backbone for computer vision trained on CIFAR-100.

<!-- task: image-classification -->
<!-- network-architecture: swin-transformer -->
<!-- dataset: cifar-100 -->
<!-- fine-tunable: false -->
<!-- license: apache-2.0 -->
<!-- format: saved_model_2 -->
<!-- asset-path: https://storage.googleapis.com/rishit-dagli/swin_transformer_model/saved_model.tar.gz -->
<!-- colab: https://colab.research.google.com/github/keras-team/keras-io/blob/master/examples/vision/ipynb/swin_transformers.ipynb -->

### TF2 SavedModel
This is a [SavedModel in TensorFlow 2 format](https://www.tensorflow.org/hub/tf2_saved_model). Using it requires TensorFlow 2 (or 1.15) and TensorFlow Hub 0.5.0 or newer.

### Overview

The Swin Transformer model, a transformer variant as proposed in the paper "Swin Transformer: Hierarchical Vision Transformer Using Shifted Windows" by Liu et al. [1] for image classification pre-trained on CiFAR-100.

Swin Transformer (Shifted Window Transformer) can serve as a general-purpose backbone for computer vision. Swin Transformer is a hierarchical Transformer whose representations are computed with shifted windows. The shifted window scheme brings greater efficiency by limiting self-attention computation to non-overlapping local windows while also allowing for cross-window connections. This architecture has the flexibility to model information at various scales and has a linear computational complexity with respect to image size.

### Usage

This model can be used with the `hub.load` as follows.

```py
model = hub.load("https://tfhub.dev/rishit-dagli/swin-transformer/1")
```

The outputs are 100 class probabilities corresponding to CIFAR-100 classes. The input images are expected to have color values in the range `[0,1]`, following the [common image input](https://www.tensorflow.org/hub/common_signatures/images#input) conventions. The expected size of the input images is height x width = 32 x 32 pixels by default.

### References

[1] Liu, Ze, et al. “Swin Transformer: Hierarchical Vision Transformer Using Shifted Windows.” ArXiv:2103.14030 [Cs], Aug. 2021. arXiv.org, http://arxiv.org/abs/2103.14030.
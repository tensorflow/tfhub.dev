# Module tensorflow/efficientnet/b3/classification/1

Imagenet (ILSVRC-2012-CLS) classification with EfficientNet-B3.

<!-- dataset: ImageNet (ILSVRC-2012-CLS) -->
<!-- asset-path: legacy -->
<!-- module-type: image-classification -->
<!-- network-architecture: EfficientNet-B3 -->
<!-- fine-tunable: true -->
<!-- format: saved_model_2 -->

## Note: requires TensorFlow 2.2+

This model requires TensorFlow 2.2 or newer, because it contains
a `FusedBatchNormV3` op with attr `exponential_avg_factor`.

## Overview

EfficientNets are a family of image classification models, which achieve
state-of-the-art accuracy, yet being an order-of-magnitude smaller and faster
than previous models.

*   Mingxing Tan and Quoc V. Le:
    [EfficientNet: Rethinking Model Scaling for Convolutional Neural Networks](https://arxiv.org/abs/1905.11946),
    ICML 2019.

We develop EfficientNets based on AutoML and Compound Scaling. In particular, we
first use
[AutoML MNAS Mobile framework](https://ai.googleblog.com/2018/08/mnasnet-towards-automating-design-of.html)
to develop a mobile-size baseline network, named as `EfficientNet-B0`; Then, we
use the compound scaling method to scale up this baseline to obtain
`EfficientNet-B1` to `EfficientNet-B7`.

This TF-Hub module uses the Keras based implementation of
`EfficientNet-B3`. The default signature is used to classify images. Besides,
the module contains a trained instance of the network, packaged to do the
[image classification](https://www.tensorflow.org/hub/common_signatures/images#classification)
that the network was trained on. We also offer a set of feature vectors to fit
different downstream tasks.

## Training

The weights for this module were obtained by training on the ILSVRC-2012-CLS
dataset for image classification ("Imagenet") with
[AutoAugment](https://arxiv.org/abs/1805.09501) preprocessing.

Please check out the
[TF Model Garden EfficientNet repository](https://github.com/tensorflow/models/tree/master/official/vision/image_classification)
for model training.

## Usage

This module implements the common signature for
[image classification](https://www.tensorflow.org/hub/common_signatures/images#classification).
It can be used like

```python
m = tf.keras.Sequential([
    hub.KerasLayer("https://tfhub.dev/tensorflow/efficientnet/b3/classification/1")
])
m.build([None, expect_img_size, expect_img_size, 3])  # Batch input shape.
```

The indices into logits are the `num_classes` = 1000 classes of the
classification from the original training (see above). The mapping from indices
to class labels can be found in the file at
[download.tensorflow.org/data/ImageNetLabels.txt](https://storage.googleapis.com/download.tensorflow.org/data/ImageNetLabels.txt)
and please ignore the first background class, ie. index 0 corresponds to
"tench".

For this model, the size of the input image is flexible, but it would be best
to match the model training input, which is `height` x `width` = 300 x 300
pixels for this model. The input `images` are expected to have color values in
the range [0,1], following the
[common image input](https://www.tensorflow.org/hub/common_signatures/images#input)
conventions.

## Fine-tuning

This model can be used with the `hub.KerasLayer` as shown in the example. It
*cannot* be used with the `hub.Module` API for TensorFlow 1.

## EfficientNet collection

See the collection of all EfficientNet models
[here](https://tfhub.dev/google/collections/efficientnet/1).

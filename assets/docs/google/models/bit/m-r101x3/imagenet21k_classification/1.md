# Module google/bit/m-r101x3/imagenet21k_classification/1

ImageNet-21k multi-label classification with the BiT-M R101x3 model.

<!-- dataset: ImageNet-21k -->
<!-- asset-path: legacy -->
<!-- fine-tunable: true -->
<!-- format: saved_model_2 -->
<!-- module-type: image-classification -->
<!-- network-architecture: ResNet101x3-v2 -->


## Overview

Big Transfer (BiT) is a recipe for pre-training image classification models on
large supervised datasets and efficiently fine-tuning them on any given target
task. The recipe achieves excellent performance on a wide variety of tasks,
even when using very few labeled examples from the target dataset.

* A. Kolesnikov, L. Beyer, X. Zhai, J. Puigcerver, J. Yung, S. Gelly and
  N. Houlsby:
  [Big Transfer (BiT): General Visual Representation Learning](https://arxiv.org/abs/1912.11370).

In the paper, three families of models are presented: "BiT-S", pre-trained on
ImageNet-1k (also known as ILSRCV-2012-CLS); "BiT-M", pre-trained on
ImageNet-21k (also known as the "Full ImageNet, Fall 2011 release");
and "BiT-L", pre-trained on JFT-300M, a proprietary dataset.

Each family is composed of a ResNet-50 (R50x1), a ResNet-50 three times wider
(R50x3), a ResNet-101 (R101x1), a ResNet-101 three times wider (R101x3), and our
flagship architecture, a ResNet-152 four times wider (R152x4). Contrary to the
original ResNet architecture, we used Group Normalization instead of Batch
Normalization, and Weight Standardization of the convolution kernels.

This module implements the R101x3 architecture, trained to perform
multi-label classification on ImageNet-21k, a dataset with 14 milion images
labeled with 21,843 classes.
Its outputs are the logits (before the sigmoid activation), and can be used to
detect the presence or absence of multiple classes of objects in the image.

If you have used this architecture, please refer to it as
**BiT-M R101x3** and cite the aforementioned work.

## Usage

```python
module = hub.KerasLayer("https://tfhub.dev/google/bit/m-r101x3/imagenet21k_classification/1")
images = ...  # A batch of images with shape [batch_size, height, width, 3].
logits = module(images)  # Logits with shape [batch_size, 21843].
probabilities = tf.nn.sigmoid(logits)
```

We provide the mapping from indices to
[WordNet IDs](https://storage.googleapis.com/bit_models/imagenet21k_wordnet_ids.txt)
as well as
[to words](https://storage.googleapis.com/bit_models/imagenet21k_wordnet_lemmas.txt).

## Fine-tuning

All our models can be directly fine-tuned.
If you want to fine-tune this architecture on your own dataset, please use the
[module that extracts feature vectors](https://tfhub.dev/google/bit/m-r101x3/1)
instead.
You can find the recipe that we use for fine-tuning in the BiT paper, which we
call the BiT HyperRule.

## BiT collection

If you want to use this architecture to perform feature extraction, or to
fine-tune it on a different dataset, we provided a
[specific module for doing so](https://tfhub.dev/google/bit/m-r101x3/1).

In addition, we also provided a module
[fine-tuned on the standard ILSVRC-2012-CLS](https://tfhub.dev/google/bit/m-r101x3/ilsvrc2012_classification/1)
dataset to perform image classification.

Finally, you can find the collection of all BiT models here: [https://tfhub.dev/google/collections/bit/1](https://tfhub.dev/google/collections/bit/1)

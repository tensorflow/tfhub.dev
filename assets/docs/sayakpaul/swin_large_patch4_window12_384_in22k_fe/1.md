# Module sayakpaul/swin_large_patch4_window12_384_in22k_fe/1

Fine-tunable Swin Transformer model pre-trained on the ImageNet-22k dataset.

<!-- asset-path: https://storage.googleapis.com/swin-tf/tars/swin_large_patch4_window12_384_in22k_fe.tar.gz  -->
<!-- task: image-classification -->
<!-- network-architecture: swin-transformer -->
<!-- format: saved_model_2 -->
<!-- fine-tunable: true -->
<!-- license: mit -->
<!-- colab: https://colab.research.google.com/github/sayakpaul/swin-transformers-tf/blob/main/notebooks/finetune.ipynb -->

## Overview

This model is a Swin Transformer [1] pre-trained on the ImageNet-22k dataset. You can find the complete
collection of Swin models on TF-Hub on [this page](https://tfhub.dev/sayakpaul/collections/swin/1).

You can use this model for feature extraction and fine-tuning. Please refer to
the Colab Notebook linked on this page for more details.

## Notes

* The original model weights are provided from [2]. There were ported to Keras models
(`tf.keras.Model`) and then serialized as TensorFlow SavedModels. The porting
steps are available in [3].
* If the model handle contains `s3` then please refer to [4] for more details on the architecture. It's 
original weights are available in [5].
* The model can be unrolled into a standard Keras model and you can inspect its topology.
To do so, first download the model from TF-Hub and then load it using `tf.keras.models.load_model`
providing the path to the downloaded model folder.

## References

[1] [Swin Transformer: Hierarchical Vision Transformer using Shifted Windows Liu et al.](https://arxiv.org/abs/2103.14030)

[2] [Swin Transformers GitHub](https://github.com/microsoft/Swin-Transformer)

[3] [Swin-TF GitHub](https://github.com/sayakpaul/swin-transformers-tf)

[4] [Searching the Search Space of Vision Transformer by Chen et al.](https://arxiv.org/abs/2111.14725)

[5] [AutoFormerV2 GitHub](https://github.com/silent-chen/AutoFormerV2-model-zoo)

## Acknowledgements

* [Willi](https://ch.linkedin.com/in/willi-gierke)
* [ML-GDE program](https://developers.google.com/programs/experts/)


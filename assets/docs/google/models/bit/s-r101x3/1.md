# Module google/bit/s-r101x3/1

Feature vector extraction with the BiT-S R101x3 model.

<!-- fine-tunable: true -->
<!-- asset-path: legacy -->
<!-- format: saved_model_2 -->
<!-- module-type: image-feature-vector -->
<!-- network-architecture: ResNet101x3-v2 -->


## Overview

Big Transfer (BiT) is a recipe for pre-training image classification models on
large supervised datasets and efficiently fine-tuning them on any given target
task. The recipe achieves excellent performance on a wide variety of tasks,
even when using very few labeled examples from the target dataset.

* A. Kolesnikov, L. Beyer, X. Zhai, J. Puigcerver, J. Yung, S. Gelly and
  N. Houlsby:
  [Big Transfer (BiT): General Visual Representation Learning](https://arxiv.org/abs/1912.11370).

In the paper, three families of models are presented: "BiT-S", pre-trained on
ImageNet-1k (also known as ILSRCV-2012-CLS); "BiT-M", pre-trained on
ImageNet-21k (also known as the "Full ImageNet, Fall 2011 release");
and "BiT-L", pre-trained on JFT-300M, a proprietary dataset.

Each family is composed of a ResNet-50 (R50x1), a ResNet-50 three times wider
(R50x3), a ResNet-101 (R101x1), a ResNet-101 three times wider (R101x3), and our
flagship architecture, a ResNet-152 four times wider (R152x4). Contrary to the
original ResNet architecture, we used Group Normalization instead of Batch
Normalization, and Weight Standardization of the convolution kernels.

This module implements the R101x3 architecture, trained to perform
image classification on ImageNet ILSRCV-2012-CLS, a dataset containing around
1.3 milion images labeled with 1,000 classes.
Its outputs are the 6144-dimensional feature vectors, before the
multi-label classification head. This model can be used as a feature extractor
or for fine-tuning on a new target task.

If you have used this architecture, please refer to it as
**BiT-S R101x3** and cite the aforementioned work.

## Usage

```python
module = hub.KerasLayer("https://tfhub.dev/google/bit/s-r101x3/1")
images = ...  # A batch of images with shape [batch_size, height, width, 3].
features = module(images)  # Features with shape [batch_size, 6144].
```

## Fine-tuning

All our models can be directly fine-tuned.

You can find the recipe that we use for fine-tuning in the BiT paper, which we
call the BiT HyperRule.

## BiT collection

If you want to use this architecture to perform image classification on
the standard ImageNet (ILSVRC-2012-CLS) dataset, we provided
[a specific model](https://tfhub.dev/google/bit/s-r101x3/ilsvrc2012_classification/1)
for that.

Finally, you can find the collection of all BiT models here: [https://tfhub.dev/google/collections/bit/1](https://tfhub.dev/google/collections/bit/1)

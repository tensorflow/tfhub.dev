# Lite tulasiram58827/fastspeech2/dr/1
TF Lite quantized version of the FastSpeech2 to generate mel spectrogram from text.

<!-- parent-model: tulasiram58827/fastspeech2/1 -->
<!-- asset-path: legacy -->
<!-- colab: https://colab.research.google.com/github/TensorSpeech/TensorFlowTTS/blob/master/notebooks/TensorFlowTTS_FastSpeech_with_TFLite.ipynb -->

## About FastSpeech2

Non-autoregressive text to speech (TTS) models such as FastSpeech can synthesize speech significantly faster than previous autoregressive models with comparable quality. 

- This model is trained on LJSpeech dataset.

- Pre-trained Model weights are provided in this [repository](https://github.com/TensorSpeech/TensorFlowTTS/)

- Model is quantized using `dynamic range` quantization method as described [here](https://www.tensorflow.org/lite/performance/post_training_quant).

- You can use this [notebook](https://github.com/TensorSpeech/TensorFlowTTS/blob/master/notebooks/TensorFlowTTS_FastSpeech_with_TFLite.ipynb) to convert the pre-trained models to TFLite Format.

- You can use [End to End Inference Notebook](https://github.com/tulasiram58827/TTS_TFLite/blob/main/End_to_End_TTS.ipynb) with Tacotron2, FastSpeech to generate speech from text.

- You can visit [TensorFlow TTS Repository](https://github.com/TensorSpeech/TensorFlowTTS) for other TTS models.

- You can visit [TTS TFLite Repository](https://github.com/tulasiram58827/TTS_TFLite) for other TFLite models.

## References

```
@misc{ren2020fastspeech,
      title={FastSpeech 2: Fast and High-Quality End-to-End Text to Speech}, 
      author={Yi Ren and Chenxu Hu and Xu Tan and Tao Qin and Sheng Zhao and Zhou Zhao and Tie-Yan Liu},
      year={2020},
      eprint={2006.04558},
      archivePrefix={arXiv},
      primaryClass={eess.AS}
}
```


# Module cosmo-group-ethz/models/kids-cgan/1

A conditional GAN to generate KiDS-1000 weak lensing surveys.

<!-- asset-path: https://people.phys.ethz.ch/~ipa/jafluri/cGAN/model/saved_model.tar.gz -->
<!-- task: image-generator -->
<!-- fine-tunable: false -->
<!-- format: saved_model_2 -->
<!-- colab: https://colab.research.google.com/drive/1YF9OYu2EwAMLfW47jQdbthpADSfkPZPy?usp=sharing -->

## Overview

This is a conditional GAN to generate tomographic [KiDS](https://kids.strw.leidenuniv.nl/) weak lensing surveys using the same data and redshift distributions as described in [Asgari et al.](https://www.aanda.org/articles/aa/abs/2021/01/aa39070-20/aa39070-20.html) The cGAN generates the spherical data using [DeepSphere](https://github.com/deepsphere/deepsphere-cosmo-tf2) that treats the pixels on the sphere as nodes in a graph. The model and its training are described in detail in [Yiu et al.](http://arxiv.org/abs/2112.12741)

### Example Use

Please refer to our [colab notebook](https://colab.research.google.com/drive/1YF9OYu2EwAMLfW47jQdbthpADSfkPZPy?usp=sharing) for a detailed tutorial going through all functions of the model. The model generates mock KiDS-1000 surveys conditioned on the total matter density &Omega;<sub>M</sub> and fluctuation amplitude &sigma;<sub>8</sub>. Per default, the model takes a 2D array with shape (N,2) containing N sets of cosmoligical parameters (&Omega;<sub>M</sub>, &sigma;<sub>8</sub>) as an input.

```
# Load KiDS-cGAN model.
model = hub.load('https://tfhub.dev/cosmo-group-ethz/models/kids-cgan/1')

# generate surveys from parameters from combinations (Om,s8)
surveys = model([[0.26, 0.84], 
                 [0.27, 0.9]])
```

This will generate two KiDS-1000 maps, i.e. `surveys` will have a shape of `(2, 149504, 5)`. The first dimension is equivalent to the number input parameter combinations, the second corresponds to the pixels of the survey (includding padding) and the last dimension corresponds to the individual redshift bins of [Asgari et al.](https://www.aanda.org/articles/aa/abs/2021/01/aa39070-20/aa39070-20.html) The survey pixelation is done according to [healpy](https://healpy.readthedocs.io/en/latest/) and examples on how to visualize the data are provided in the [colab notebook](https://colab.research.google.com/drive/1YF9OYu2EwAMLfW47jQdbthpADSfkPZPy?usp=sharing).

### Training Data

Interested in the training data? The training data, generated as described in [Yiu et al.](http://arxiv.org/abs/2112.12741) is available [here]( https://people.phys.ethz.ch/~ipa/jafluri/cGAN/train_data). You can download individual files (~500 MB) via

```
 wget https://people.phys.ethz.ch/~ipa/jafluri/cGAN/train_data/<file_name>
```

or the entire dataset (~150 GB) via

```
wget -r -nH --cut-dirs=4 --no-parent --reject="index.html*" https://people.phys.ethz.ch/~ipa/jafluri/cGAN/train_data/
```


# Module google/edgetpu/vision/mobilenet-edgetpu-v2/l/1

MobileNet-EdgeTPU-v2 is a set of image classification models that are optimized
for Pixel 6.

<!-- asset-path: internal -->
<!-- task: image-classification -->
<!-- fine-tunable: false -->
<!-- format: saved_model_2 -->
<!-- dataset: imagenet -->

## Overview

MobileNet-EdgeTPU-v2 is a set of image classification models that are optimized
for EdgeTPU devices via Neural Architecture Search (NAS). As one of the key
customizations of the NAS search space, we introduce group convolution based
inverted bottleneck blocks (IBN) that provide an enhanced flexibility in
achieving lower latency and higher model quality.

The large version (L) model contains 11.4M parameters, achieves **78.84% top-1
accuracy** with **537 FPS** running on Pixel 6
[Tensor SoC](https://blog.google/products/pixel/google-tensor-debuts-new-pixel-6-fall/).

## Example use

This module implements the common signature for image classification. It can be
used like:

```python

# TF2 version
import tensorflow as tf
import tensorflow_hub as hub

keras_layer =
hub.KerasLayer('https://tfhub.dev/google/edgetpu/vision/mobilenet-edgetpu-v2/l/1')
model = tf.keras.Sequential([keras_layer])
model.build([None, 224, 224, 3])
input_tensor = tf.ones((4, 224, 224, 3))
output_tensor = model(input_tensor)
```

The indices into logits are the `num_classes = 1001` classes of the
classification from the original training. The mapping from indices to class
labels can be found in the file at
download.tensorflow.org/data/ImageNetLabels.txt and index 0 corresponds to the
first background class.

For this model, the size of the input image is flexible, but it would be best to
match the model training input, which is `height x width = 224 x 224` pixels for
this model. The input images are expected to have color values in the range
[0,1], following the common image input conventions.

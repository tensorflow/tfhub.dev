# Module google/&zwnj;imagenet/&zwnj;mobilenet_v1_025_128/&zwnj;quantops/&zwnj;classification/3
Imagenet (ILSVRC-2012-CLS) classification with MobileNet V1 (depth multiplier 0.25).

<!-- dataset: ImageNet (ILSVRC-2012-CLS) -->
<!-- asset-path: legacy -->
<!-- fine-tunable: false -->
<!-- format: hub -->
<!-- module-type: image-classification -->
<!-- network-architecture: MobileNet V1 -->


## hub.Module for TF1

This is a hub.Module for use with TensorFlow 1.

For TensorFlow 2, the quantops modules are discontinued.
Instead, use plain models from TF Hub and apply TF Lite's
[post-training quantization](https://www.tensorflow.org/lite/performance/post_training_quantization).


## Overview

MobileNet V1 is a family of neural network architectures for efficient
on-device image classification, originally published by

  * Andrew G. Howard, Menglong Zhu, Bo Chen, Dmitry Kalenichenko, Weijun Wang,
    Tobias Weyand, Marco Andreetto, Hartwig Adam:
    ["MobileNets: Efficient Convolutional Neural Networks for
    Mobile Vision Applications"](https://arxiv.org/abs/1704.04861), 2017.

Mobilenets come in various sizes controlled by a multiplier for the
depth (number of features) in the convolutional layers. They can also be
trained for various sizes of input images to control inference speed.
This TF-Hub module uses the TF-Slim implementation of
`mobilenet_v1_v1_025`, **instrumented for quantization**,
with a depth multiplier of 0.25 and an input size of
128x128 pixels.

The module contains a trained instance of the network, packaged to do the
[image classification](https://www.tensorflow.org/hub/common_signatures/images#classification)
that the network was trained on. If you merely want to transform images into
feature vectors, use module
[`google/imagenet/mobilenet_v1_025_128/quantops/feature_vector/3`](https://tfhub.dev/google/imagenet/mobilenet_v1_025_128/quantops/feature_vector/3)
instead, and save the space occupied by the classification layer.


## Quantization

This module is meant for use in models whose weights will be quantized to
`uint8` by [TensorFlow Lite](https://www.tensorflow.org/mobile/tflite/)
for deployment to mobile devices.

The trained weights of this module are shipped as `float32` numbers,
but its graph has been augmented by `tf.contrib.quantize` with extra ops
that simulate the effect of quantization already during training,
so that the model can adjust to it.

## Training

The checkpoint exported into this module was `mobilenet_v1_2018_02_22/mobilenet_v1_0.25_128_quant/mobilenet_v1_0.25_128_quant.ckpt` downloaded
from
[MobileNet pre-trained models](https://github.com/tensorflow/models/blob/master/research/slim/nets/mobilenet_v1.md).
Its weights were originally obtained by training on the ILSVRC-2012-CLS
dataset for image classification ("Imagenet"), with simulated quantization.

## Usage

This module implements the common signature for
[image classification](https://www.tensorflow.org/hub/common_signatures/images#classification).
It can be used with the `hub.Module` API like

```python
module = hub.Module("https://tfhub.dev/google/imagenet/mobilenet_v1_025_128/quantops/classification/3")
height, width = hub.get_expected_image_size(module)
images = ...  # A batch of images with shape [batch_size, height, width, 3].
logits = module(images)  # Logits with shape [batch_size, num_classes].
```

...or using the signature name `image_classification`.
For use with TF2 APIs, see TF Hub's [migration
guide](https://github.com/tensorflow/hub/blob/master/docs/migration_tf2.md).

The indices into logits
are the `num_classes` = 1001 classes of the classification from
the original training (see above). The mapping from indices to class labels
can be found in the file at [download.tensorflow.org/data/ImageNetLabels.txt](https://storage.googleapis.com/download.tensorflow.org/data/ImageNetLabels.txt).

This module can also be used to compute [image feature
vectors](https://www.tensorflow.org/hub/common_signatures/images#feature-vector),
using the signature name `image_feature_vector`.

The input `images` are expected to have color values in the range [0,1],
following the
[common image input](https://www.tensorflow.org/hub/common_signatures/images#input)
conventions.
For this module, the size of the input images is fixed to
`height` x `width` = 128 x 128 pixels.


## Fine-tuning

The current version of this module only provides an inference graph
and cannot be fine-tuned.


## Changelog

#### Version 1

  * Initial release.

#### Version 3

  * Avoids crash in some TFLite/toco versions
    ([GitHub issue 109](https://github.com/tensorflow/hub/issues/109))
    by overestimating quantization boundaries on input image by 0.05%.
  * Requires PIP package `tensorflow-hub>=0.2.0`.

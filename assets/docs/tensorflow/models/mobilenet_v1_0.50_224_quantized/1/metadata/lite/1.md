# Lite tensorflow/mobilenet_v1_0.50_224_quantized/1/metadata/1
TF Lite deployment of tensorflow/mobilenet_v1_0.50_224_quantized/1.

<!-- asset-path: legacy -->
<!-- parent-model: tensorflow/mobilenet_v1_0.50_224_quantized/1 -->
<!-- interactive-visualizer: tflite_image_classifier -->

## Description
Pre-trained model optimized to work with TensorFlow Lite.
This model contains both TFLite model metadata and the label file.
[TFLite metadata](https://www.tensorflow.org/lite/convert/metadata) is a rich
model description including both human and machine readable information.

## Resources

-   A [model list](https://www.tensorflow.org/lite/models/image_classification/overview)
    together with the performance stats is available.

-   Running demo apps and examples for Android and iOS can be found on
    [github](https://github.com/tensorflow/examples/blob/master/lite/examples/image_classification).

## Inputs

Image data: `ByteBuffer` sized `224 x 224 x 3 x PIXEL_DEPTH`, where
`PIXEL_DEPTH` is `4` for float model, and `1` for quantized model.

## Outputs

Probability, a float array of size `[1][NUM_CLASS]`, where `NUM_CLASS = 1001` is
the number of classes.

## Usage

Java code:

```
File tfliteModel = "***.tflite";
tflite = new Interpreter(tfliteModel);  # Load model.

final float IMAGE_MEAN = 127.5f;
final float IMAGE_STD = 127.5f;
final int IMAGE_SIZE_X = 224;
final int IMAGE_SIZE_Y = 224;
final int DIM_BATCH_SIZE = 1;
final int DIM_PIXEL_SIZE = 3;
final int NUM_BYTES_PER_CHANNEL = 4;  # Quantized model is 1
final int NUM_CLASS = 1001;

// The example uses Bitmap ARGB_8888 format.
Bitmap bitmap = ...;

int[] intValues = new int[IMAGE_SIZE_X * IMAGE_SIZE_Y];
bitmap.getPixels(intValues, 0, bitmap.getWidth(), 0, 0, bitmap.getWidth(), bitmap.getHeight());

ByteBuffer imgData =
    ByteBuffer.allocateDirect(
        DIM_BATCH_SIZE
            * IMAGE_SIZE_X
            * IMAGE_SIZE_Y
            * DIM_PIXEL_SIZE
            * NUM_BYTES_PER_CHANNEL);
imgData.rewind();

// Float model.
int pixel = 0;
for (int i = 0; i < IMAGE_SIZE_X; ++i) {
  for (int j = 0; j < IMAGE_SIZE_Y; ++j) {
    int pixelValue = intValues[pixel++];
    imgData.putFloat((((pixelValue >> 16) & 0xFF) - IMAGE_MEAN) / IMAGE_STD);
    imgData.putFloat((((pixelValue >> 8) & 0xFF) - IMAGE_MEAN) / IMAGE_STD);
    imgData.putFloat(((pixelValue & 0xFF) - IMAGE_MEAN) / IMAGE_STD);
  }
}

// Quantized model.
int pixel = 0;
for (int i = 0; i < IMAGE_SIZE_X; ++i) {
  for (int j = 0; j < IMAGE_SIZE_Y; ++j) {
    imgData.put((byte) ((pixelValue >> 16) & 0xFF));
    imgData.put((byte) ((pixelValue >> 8) & 0xFF));
    imgData.put((byte) (pixelValue & 0xFF));
  }
}

// Output label probabilities.
float[][] labelProbArray = new float[1][NUM_CLASS];

// Run the model.
tflite.run(imgData, labelProbArray);
```

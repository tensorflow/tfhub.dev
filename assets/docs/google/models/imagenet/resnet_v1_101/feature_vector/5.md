# Module google/imagenet/resnet_v1_101/feature_vector/5
Feature vectors of images with ResNet V1 101 trained on ImageNet (ILSVRC-2012-CLS).

<!-- asset-path: internal -->
<!-- dataset: imagenet-ilsvrc-2012-cls -->
<!-- fine-tunable: true -->
<!-- format: saved_model_2 -->
<!-- module-type: image-feature-vector -->
<!-- network-architecture: ResNet V1 101 -->

## TF2 SavedModel

This is a [SavedModel in TensorFlow 2
format](https://www.tensorflow.org/hub/tf2_saved_model).
Using it requires TensorFlow 2 (or 1.15) and TensorFlow Hub 0.5.0 or newer.

## Overview

ResNet (later renamed ResNet V1) is a family of network architectures for
image classification with a variable number of layers, originally
published by

  * Kaiming He, Xiangyu Zhang, Shaoqing Ren, Jian Sun: ["Deep Residual Learning
    for Image Recognition"](https://arxiv.org/abs/1512.03385), 2015.

This TF Hub model uses the TF-Slim implementation of `resnet_v1_101`
with 101 layers.
The model contains a trained instance of the network, packaged to get
[feature vectors from images](https://www.tensorflow.org/hub/common_signatures/images#feature-vector).
If you want the full model including the classification it was originally
trained for, use
[`google/imagenet/resnet_v1_101/classification/5`](https://tfhub.dev/google/imagenet/resnet_v1_101/classification/5)
instead.


## Training

The weights for this model were obtained by training on the ILSVRC-2012-CLS
dataset for image classification ("Imagenet") with TF-Slim's "Inception-style"
preprocessing.


## Usage

This model can be used with the `hub.KerasLayer` as follows.
It *cannot* be used with the `hub.Module` API for TensorFlow 1.

```python
m = tf.keras.Sequential([
    hub.KerasLayer("https://tfhub.dev/google/imagenet/resnet_v1_101/feature_vector/5",
                   trainable=False),  # Can be True, see below.
    tf.keras.layers.Dense(num_classes, activation='softmax')
])
m.build([None, 224, 224, 3])  # Batch input shape.
```

The output is a batch of feature vectors. For each input image,
the feature vector has size `num_features` = 2048. The feature
vectors can then be used further, e.g., for classification as above.

The input `images` are expected to have color values in the range [0,1],
following the
[common image input](https://www.tensorflow.org/hub/common_signatures/images#input)
conventions.
The expected size of the input images is
`height` x `width` = 224 x 224 pixels
by default, but other input sizes are possible (within limits).


## Fine-tuning

Consumers of this model can
[fine-tune](https://www.tensorflow.org/hub/tf2_saved_model#fine-tuning) it
by passing `trainable=True` to `hub.KerasLayer`.

The momentum (a.k.a. decay coefficient) of batch norm's exponential moving
averages defaults to 0.99 for this model, in order to accelerate training
on small datasets (or with huge batch sizes).
Advanced users can set another value (say, 0.997) by loading this model like

```python
hub.KerasLayer("https://tfhub.dev/google/imagenet/resnet_v1_101/feature_vector/5",
               trainable=True, arguments=dict(batch_norm_momentum=0.997))
```


## Changelog

#### Version 1

  * Initial release.

#### Version 3

  * Support for variable input size.
  * Fine-tuning: change default batch norm momentum to 0.99 and
    make it configurable.
  * Requires PIP package `tensorflow-hub>=0.2.0`.

#### Version 4

  * Switched to the SavedModel format of TensorFlow 2.
    The `hub.Module` class cannot load this or later versions any more.

#### Version 5

  * Add 'serving_default' SignatureDef
  * Fix bug if using models with `tf.GradientTape(persistent=True)`

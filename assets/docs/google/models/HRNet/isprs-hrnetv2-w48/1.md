# Module google/HRNet/isprs-hrnetv2-w48/1

HRNet based model trained on the semantic segmentation dataset ISPRS [4].

<!-- asset-path: internal -->
<!-- task: image-segmentation -->
<!-- fine-tunable: false -->
<!-- format: saved_model_2 -->
<!-- format: saved_model_2 -->
<!-- network-architecture: hrnet-v2-w48 -->
<!-- dataset: isprs -->


## HRNet Overview

This is an [HRNet](https://arxiv.org/abs/2204.01403) [3] segmentation model trained on ISPRS [4]. It is part of a large suite of pre-trained segmentation models released as part of a benchmark for evaluating transferability metrics, as described in ["How stable are Transferability Metrics evaluations?"](https://arxiv.org/abs/2204.01403) [1]. More information about the specific architecture and training procedure used can be found in ["Factors of Influence for Transfer Learning across Diverse Appearance Domains and Task Types"](https://arxiv.org/abs/2103.13318) [2].

### Datasets Overview

The model has been pre-trained on the imagenet-ilsvrc-2012-cls classification task [5], and fine-tuned on ISPRS [4]. ISPRS is a semantic segmentation dataset with images from the aerial domain, it contains 6 different classes. For additional information we refer to the [factors of influence dataset collection](https://github.com/google-research/google-research/tree/master/factors_of_influence) on how to use it.


### Example use.

```python 
import tensorflow as tf
import tensorflow_datasets as tfds
import tensorflow_hub as hub 

model = hub.load('https://tfhub.dev/google/HRNet/isprs-hrnetv2-w48/1')

ds = tfds.load('scene_parse150', split='train', with_info=False)
img = next(iter(ds))['image']
img = tf.cast([img], tf.float32)/255.0

# Predictions will have shape (batch_size, h, w, output_classes=6+1)
# Note: an additional class is added for the background.
predictions = model.predict([img])
# Features will have shape (batch_size, h/4, w/4, 720)
features = model.get_features([img])
```

#### References

[1] Agostinelli, Andrea, et al. "How stable are Transferability Metrics evaluations?." arXiv preprint arXiv:2204.01403 (2022).

[2] Mensink, Thomas, et al. "Factors of Influence for Transfer Learning across Diverse Appearance Domains and Task Types." IEEE Transactions on Pattern Analysis & Machine Intelligence 01 (2021): 1-1.

[3] Wang, Jingdong, et al. "Deep high-resolution representation learning for visual recognition." IEEE transactions on pattern analysis and machine intelligence 43.10 (2020): 3349-3364.

[4] Rottensteiner, F., Sohn, G., Gerke, M., Wegner, J.D., Breitkopf, U., Jung, J.:
Results of the isprs benchmark on urban object detection and 3d building reconstruction. ISPRS journal of photogrammetry and remote sensing (2014).

[5] Russakovsky, O., Deng, J., Su, H., Krause, J., Satheesh, S., Ma, S., Huang, Z.,
Karpathy, A., Khosla, A., Bernstein, M., Berg, A., Fei-Fei, L.: ImageNet large
scale visual recognition challenge. IJCV (2015).

# Lite svampeatlas/vision/classifier/fungi_mobile_V1/1/default/1
TF Lite deployment of svampeatlas/vision/classifier/fungi_mobile_V1/1.

<!-- asset-path: legacy -->
<!-- parent-model: svampeatlas/vision/classifier/fungi_mobile_V1/1 -->

## Description

Mobile-compatible image classification model trained on Fungi dataset provided
by the Danish Mycological Society, optimized to work with TensorFlow Lite.

## Resources

*   [Labelmap](https://www.gstatic.com/aihub/tfhub/labelmaps/fungiv2_labelmap.csv).

## Inputs

Image data: `ByteBuffer` sized `HEIGHT x WIDTH x 3`, where `HEIGHT = 299` and
`WIDTH = 299`.

## Outputs

Probability, a float array of size `[1][NUM_CLASSES]`, where `NUM_CLASSES =
4128` is the number of classes.

## Usage

Java code:

```java
File tfliteModel = new File("***.tflite");
Interpreter tflite = new Interpreter(tfliteModel);  // Load model.

final int IMAGE_SIZE_X = 299;
final int IMAGE_SIZE_Y = 299;
final int DIM_BATCH_SIZE = 1;
final int DIM_PIXEL_SIZE = 3;
final int NUM_BYTES_PER_CHANNEL = 1;
final int NUM_CLASSES = 4128;

// The example uses Bitmap ARGB_8888 format.
Bitmap bitmap = ...;

int[] intValues = new int[IMAGE_SIZE_X * IMAGE_SIZE_Y];
bitmap.getPixels(intValues, 0, bitmap.getWidth(), 0, 0, bitmap.getWidth(), bitmap.getHeight());

ByteBuffer imgData =
    ByteBuffer.allocateDirect(
        DIM_BATCH_SIZE
            * IMAGE_SIZE_X
            * IMAGE_SIZE_Y
            * DIM_PIXEL_SIZE
            * NUM_BYTES_PER_CHANNEL);
imgData.rewind();

// Quantized model.
int pixel = 0;
for (int i = 0; i < IMAGE_SIZE_X; ++i) {
  for (int j = 0; j < IMAGE_SIZE_Y; ++j) {
    int pixelValue = intValues[pixel++];
    imgData.put((byte) ((pixelValue >> 16) & 0xFF));
    imgData.put((byte) ((pixelValue >> 8) & 0xFF));
    imgData.put((byte) (pixelValue & 0xFF));
  }
}

// Output label probabilities.
float[][] labelProbArray = new float[1][NUM_CLASSES];

// Run the model.
tflite.run(imgData, labelProbArray);

// Close the interpreter to avoid leaking resources.
tflite.close()
```

Python code:

```python
# Load the model
interpreter = tf.lite.Interpreter(model_path='***.tflite')
interpreter.allocate_tensors()

# Get input and output tensors.
input_details = interpreter.get_input_details()
output_details = interpreter.get_output_details()

# Load image data with dtype=np.uint8
input_data = ...
# The input data's shape should match input_details[0]['shape'], which is
# BATCH_SIZE x HEIGHT (299) x WIDTH (299) x CHANNELS (3)
interpreter.set_tensor(input_details[0]['index'], input_data)

interpreter.invoke()

# The function `get_tensor()` returns a copy of the tensor data.
# Use `tensor()` in order to get a pointer to the tensor.
output_data = interpreter.get_tensor(output_details[0]['index'])

```

## Benchmarks

Benchmarks for the TF Lite deployment of
svampeatlas/vision/classifier/fungi_mobile_V1/1.

**Model Size (on disk):** 30MB

Latency measured on Pixel 3, Pixel 4, Pixel 4 XL and iPhone Xs.

Power and memory measured on Pixel 3, Pixel 4, Pixel 4 XL.

### Terminology

*   [NNAPI](https://developer.android.com/ndk/guides/neuralnetworks)
*   Total PSS:
    [Proportional Set Size](https://en.wikipedia.org/wiki/Proportional_set_size)

### Charts

![Mean Latency (ms)](https://www.gstatic.com/aihub/tfhub/charts/fungi_mobile_V1/mean_latency_ms.png)

![Mean Current (mA)](https://www.gstatic.com/aihub/tfhub/charts/fungi_mobile_V1/mean_current_ma.png)

![Mean Power (mW)](https://www.gstatic.com/aihub/tfhub/charts/fungi_mobile_V1/mean_power_mw.png)

![Mean Energy (mJ)](https://www.gstatic.com/aihub/tfhub/charts/fungi_mobile_V1/mean_energy_mj.png)

![Mean Low-core Frequency (GHz)](https://www.gstatic.com/aihub/tfhub/charts/fungi_mobile_V1/mean_low_core_frequency_ghz.png)

![Mean High-core Frequency (GHz)](https://www.gstatic.com/aihub/tfhub/charts/fungi_mobile_V1/mean_high_core_frequency_ghz.png)

![RAM Total PSS (kB)](https://www.gstatic.com/aihub/tfhub/charts/fungi_mobile_V1/ram_total_pss_kb.png)

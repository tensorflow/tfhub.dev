# Lite monatis/german-mbmelgan/lite/1
TF Lite version of German Multi-band MelGAN as described in [1].

<!-- parent-model: monatis/german-mbmelgan/1 -->
<!-- asset-path: https://storage.googleapis.com/mys-released-models/german-tts-mbmelgan-lite.tar.gz -->

## Overview
This is the TF Lite version of German Multi-band MelGAN to be used with TF Lite library. It is a mel-to-speech model to be used for neural text-to-speech synthesis, and You need a text-to-mel model, e.g. Tacotron 2 (also published on TF Hub), to get MEL spectagrams first. See [monatis/german-tts](https://github.com/monatis/german-tts) repo on GitHub for an end-to-end inference example.

## Dataset
I trained these models on [Thorsten dataset](https://github.com/thorstenMueller/deep-learning-german-tts) by Thorsten MÃ¼ller. It is licensed under the terms of Creative Commons Zero V1 Universal (CC0), which is used to opt out of copyright entirely and ensure that the work has the widest reach. Thanks [@thorstenMueller](https://github.com/thorstenMueller) for such a great contribution to the community.

## Notes
- I made use of [german_transliterate](https://github.com/repodiac/german_transliterate) For text preprocessing. Basically it normalizes numbers (e.g. converts digits to words), expands abbreviations and cares German umlauts and punctuations. For inference examples released in this repo, it is the only dependency apart from TensorFlow.
- You need to convert input text to numerical IDs to feed into the model. I am sharing a reference implementation for this in inference examples, and you need to code this logic to use the models in non-Python environments (e.g., Android).
- I exported Multi-band MelGAN to TF Lite without optimizations because it produced some background noise when I exported with the default ones. 

#### References
[1] Geng Yang, Shan Yang, Kai Liu, Peng Fang, Wei Chen, Lei Xie. Multi-band MelGAN: Faster Waveform Generation for High-Quality Text-to-Speech. https://arxiv.org/abs/2005.05106

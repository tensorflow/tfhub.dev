# Module google/tiny_video_net/mobile_1/1

A fast model to recognize actions in videos.

<!-- asset-path: internal -->
<!-- module-type: video-classification -->
<!-- fine-tunable: true -->
<!-- format: hub -->
<!-- network-architecture: tvn-mobile-1 -->
<!-- dataset: charades -->

## Overview

This is one of the Tiny Video Networks designed to recognize actions in videos.
The model takes a video as input and outputs labels of the occurring actions in
video. The models are the result of an architecture search, done to find fast
models that can run in real time on a variety of devices while still taking
advantage of temporal information to recognize actions.

More details about the model can be found in the papers: "Tiny Video Networks"
AJ Piergiovanni, Anelia Angelova, and Michael S. Ryoo
https://www.automl.org/wp-content/uploads/2020/07/AutoML_2020_paper_17.pdf
published at ICML AutoML Workshop, 2020 and on arXiv:
https://arxiv.org/abs/1910.06961

### Example use. The model takes a video as input and classifies the occurring actions.

```python


import numpy as np
# TF1 version
import tensorflow.compat.v1 as tf
import tensorflow_hub as hub

model_handle = 'https://tfhub.dev/google/tiny_video_net/mobile_1/1'
model = hub.Module(model_handle)

vid_placeholder = tf.placeholder(tf.float32,
                                 shape=(batch_size * num_frames,
                                        image_size, image_size, 3))

# This generates a random video. It should be replaced by a user's video.
# video = load_video(video_path) which should return a video of the above shape.
video = np.random.rand(*vid_placeholder.shape)

predictions = model(video)

```

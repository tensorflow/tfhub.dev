# Module google/tf2-preview/inception_v3/classification/2
[TF2] Imagenet (ILSVRC-2012-CLS) classification with Inception V3.

<!-- dataset: imagenet-ilsvrc-2012-cls -->
<!-- asset-path: legacy -->
<!-- module-type: image-classification -->
<!-- task: image-classification -->
<!-- network-architecture: inception-v3 -->
<!-- fine-tunable: true -->
<!-- format: saved_model_2 -->




## TensorFlow 2.0 Preview

This module uses the SavedModel 2.0 format and was created to help
preview TensorFlow 2.0 functionality. Using it requires the (currently
experimental) library versions TensorFlow 2.0 and TensorFlow Hub 0.3.0.

## Overview

Inception V3 is a neural network architecture for image classification,
originally published by

  * Christian Szegedy, Vincent Vanhoucke, Sergey Ioffe, Jonathon Shlens,
    Zbigniew Wojna: ["Rethinking the Inception Architecture for Computer
    Vision"](https://arxiv.org/abs/1512.00567), 2015.

This TF-Hub module uses the TF-Slim implementation of `inception_v3`.
The module contains a trained instance of the network, packaged to do the
[image classification](https://www.tensorflow.org/hub/common_signatures/images#classification)
that the network was trained on. If you merely want to transform images into
feature vectors, use module
[`google/tf2-preview/inception_v3/feature_vector/2`](https://tfhub.dev/google/tf2-preview/inception_v3/feature_vector/2)
instead, and save the space occupied by the classification layer.


## Training

The checkpoint exported into this module was `inception_v3_2016_08_28/inception_v3.ckpt` downloaded
from
[TF-Slim's pre-trained models](https://github.com/tensorflow/models/blob/master/research/slim/README.md#pre-trained-models).
Its weights were originally obtained by training on the ILSVRC-2012-CLS
dataset for image classification ("Imagenet").


## Usage

This module can be used with the `hub.KerasLayer` as follows:

```python
m = tf.keras.Sequential([
    hub.KerasLayer("https://tfhub.dev/google/tf2-preview/inception_v3/classification/2", output_shape=[1001])
])
m.build([None, 299, 299, 3])  # Batch input shape.
```

The output is a batch of logits vectors. The indices into the logits
are the `num_classes` = 1001 classes of the classification from
the original training (see above). The mapping from indices to class labels
can be found in the file at [download.tensorflow.org/data/ImageNetLabels.txt](https://storage.googleapis.com/download.tensorflow.org/data/ImageNetLabels.txt).

For this module, the size of the input image is fixed to
`height` x `width` = 299 x 299 pixels.
The input `images` are expected to have 3 RGB color values in the range [0,1],
following the
[common image input](https://www.tensorflow.org/hub/common_signatures/images#input)
conventions (analogously to TF 1.x).


## Fine-tuning

In principle, consumers of this module can
[fine-tune](https://www.tensorflow.org/hub/tf2_saved_model#fine-tuning) it
by passing `trainable=True` to `hub.KerasLayer`.
(Calling it while trainable automatically updates the moving averages of
batch normalization.)

However, fine-tuning through a large classification might be prone to overfit.


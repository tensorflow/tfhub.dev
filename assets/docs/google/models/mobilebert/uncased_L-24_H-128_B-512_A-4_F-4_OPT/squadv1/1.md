# Module google/mobilebert/uncased_L-24_H-128_B-512_A-4_F-4_OPT/squadv1/1

MobileBert retrained on SQuAD 1.1

<!-- asset-path: internal -->
<!-- module-type: text-embedding -->
<!-- fine-tunable: true -->
<!-- format: hub -->
<!-- language: en -->
<!-- network-architecture: mobilebert-uncased_l-24_h-128_b-512_a-4_f-4_opt -->
<!-- dataset: squad -->

## Overview

MobileBERT is a thin version of BERT, while equipped with bottleneck structures
and a carefully designed balance between self-attentions and feed-forward
networks.

*   Zhiqing Sun, Hongkun Yu, Xiaodan Song, Renjie Liu, Yiming Yang, Denny Zhou:
    ["MobileBERT: a Compact Task-Agnostic BERT for Resource-Limited Devices"](https://arxiv.org/abs/2004.02984), 2020.

This TF Hub model uses the implementation of MobileBERT from the Google Research
repository on GitHub at
[google-research/google-research/tree/master/mobilebert](https://github.com/google-research/google-research/tree/master/mobilebert).
The
[model configuration](https://github.com/google-research/google-research/blob/master/mobilebert/config/uncased_L-24_H-128_B-512_A-4_F-4_OPT.json)
is a variant of Transformer with L=24 hidden layers (i.e., Transformer blocks),
a hidden size of H=128, B=512 as bottleneck size, A=4 attention heads, and F=4
inner feed-forward layers.

This model is retrained on SQuAD1.1 in
[run_squad.py](https://github.com/google-research/google-research/tree/master/mobilebert/run_squad.py).
This model could be directly used in question answering task or further
fine-tuned on other question answering dataset.

## Usages

This model is called as follows on tokenized text input, an input mask to hold
out padding tokens, and segment types when input mixes with different segments.

```python
import tensorflow.compat.v1 as tf
import tensorflow_hub as hub

tags = set(["train"])
hub_url = 'https://tfhub.dev/google/mobilebert/uncased_L-24_H-128_B-512_A-4_F-4_OPT/squadv1/1'
bert_module = hub.Module(hub_url, tags=tags, trainable=True)
bert_inputs = dict(
    input_ids=input_ids, input_mask=input_mask, segment_ids=segment_ids)
bert_outputs = bert_module(bert_inputs, signature="squad", as_dict=True)
start_logits = bert_outputs["start_logits"]
end_logits =  bert_outputs["end_logits"]
```

This module is used in
[TensorFlow Lite Model Maker](https://www.tensorflow.org/lite/guide/model_maker)
in the
[question answer task](https://www.tensorflow.org/lite/tutorials/model_maker_question_answer).

The models in the TensorFlow Lite format and JavaScript format are also released
shown on
[Tensorflow Hub](https://tfhub.dev/tensorflow/lite-model/mobilebert/1/default/1).

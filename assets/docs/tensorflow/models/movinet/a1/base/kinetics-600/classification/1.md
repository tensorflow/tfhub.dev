# Module tensorflow/movinet/a1/base/kinetics-600/classification/1

MoViNets (Mobile Video Networks) for efficient video classification with MoViNet-A1-Base.

<!-- asset-path: internal -->
<!-- dataset: Kinetics 600 -->
<!-- fine-tunable: true -->
<!-- format: saved_model_2 -->
<!-- language: en -->
<!-- module-type: video-classification -->
<!-- network-architecture: MoViNet -->

## Overview

MoViNets (Mobile Video Networks) provide a family of efficient video
classification models, supporting inference on streaming video.

* Dan Kondratyuk, Liangzhe Yuan, Yandong Li, Li Zhang, Matthew Brown, and
Boqing Gong. [MoViNets: Mobile Video Networks for Efficient Video Recognition](https://arxiv.org/abs/2103.11511). 2021.

This TF Hub model uses the implementation of MoViNets from the TensorFlow
Models repository on GitHub at
[tensorflow/models/official/vision/beta/projects/movinet](https://github.com/tensorflow/models/tree/master/official/vision/beta/projects).

This model expects an RGB 5D video tensor as input. For this model, the size of
the input video is flexible, but it would be best to
match the model training resolution and frame-rate, which is height x width =
172 x 172 at 5 fps. The input videos are
expected to have color values in the range [0,1], following the common
[image input conventions](https://www.tensorflow.org/hub/common_signatures/images#input).

## Usage

This model supports training and inference in TF 2.

The simplest way to use this model in the
[Keras functional API](https://www.tensorflow.org/guide/keras/functional)
is

```python
import tensorflow as tf
import tensorflow_hub as hub

inputs = tf.keras.layers.Input(
    shape=[None, None, None, 3],
    dtype=tf.float32)

encoder = hub.KerasLayer(
    "https://tfhub.dev/tensorflow/movinet/a1/base/kinetics-600/classification/1")

# Important: due to a bug in the tf.nn.conv3d CPU implementation, we must
# compile with tf.function to enforce correct behavior. Otherwise, the output
# on CPU may be incorrect.
encoder.call = tf.function(encoder.call, experimental_compile=True)

# [batch_size, 600]
outputs = encoder(dict(image=inputs))

model = tf.keras.Model(inputs, outputs)

example_input = tf.ones([1, 8, 172, 172, 3])
example_output = model(example_input)
print(example_output)
```

### Fine-Tuning

This model can be used with the `hub.KerasLayer` and wrapped in a
`tf.keras.Model` as shown in the example. Calling [`model.fit()`](https://www.tensorflow.org/api_docs/python/tf/keras/Model#fit)
will enable fine-tuning using the pretrained weights.

### Training

Please check out the [TF Model Garden MoViNet repository](https://github.com/tensorflow/models/tree/master/official/vision/beta/projects)
for model training.

## Version 1

* Initial release.

## MoViNet Collection

See the collection of all MoViNet models [here](https://tfhub.dev/google/collections/movinet/1)

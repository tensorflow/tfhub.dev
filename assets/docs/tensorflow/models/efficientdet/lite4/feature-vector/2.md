# Module tensorflow/efficientdet/lite4/feature-vector/2

EfficientDet-Lite Object detection model, trained on COCO 2017 dataset,
optimized for TFLite, designed for performance on mobile CPU, GPU, and EdgeTPU.

<!-- asset-path: internal -->
<!-- module-type: image-object-detection -->
<!-- fine-tunable: true -->
<!-- format: saved_model_2 -->
<!-- network-architecture: EfficientDet -->
<!-- dataset: COCO 2017 -->

## Overview

EfficientDet-Lite are a family of mobile/IoT-friendly object detection models.
They are derived from the EfficientDet architecture originally published as:

*   Mingxing Tan, Ruoming Pang, Quoc V. Le:
    [EfficientDet: Scalable and Efficient Object Detection](https://arxiv.org/abs/1911.09070),
    CVPR 2020.

EfficientDet-Lite runs well on all mobile CPU/GPU/EdgeTPU hardware.

This TF Hub model uses the implementation of EfficientDet-Lite from the
[Google AutoML repository](https://github.com/google/automl/tree/master/efficientdet)
on GitHub . The model configuration is shown in
[code](https://github.com/google/automl/blob/ea9d3c58f48f8e99bad0119a7b3a1ad5953481e0/efficientdet/hparams_config.py#L383).

### Example usage

```python
image = ...  # A batch of preprocessed images with shape [batch_size, height, width, 3].
base_model = hub.KerasLayer("https://tfhub.dev/tensorflow/efficientdet/lite4/feature-vector/1")
cls_outputs, box_outputs = base_model(image, training=training)
```

The size of the input image is `height` x `width` = 640 x 640 pixels for this
model. The input `images` are expected to have color values in the range [-1,
1].

For complete usage examples, see
[train_lib.py](https://github.com/google/automl/blob/ea9d3c58f48f8e99bad0119a7b3a1ad5953481e0/efficientdet/keras/train_lib.py#L854)
from
[automl/efficientdet/](https://github.com/google/automl/tree/ea9d3c58f48f8e99bad0119a7b3a1ad5953481e0/efficientdet)
on GitHub.

#### Metrics

Metric                    | Value | Outputs
------------------------- | ----- | -------
mAP on COCO 2017 eval set | 44.5  | Boxes

#### Release Notes

v2 - updated the model with `image_size=640x640`.

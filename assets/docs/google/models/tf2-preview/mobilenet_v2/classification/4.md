# Module google/&zwnj;tf2-preview/&zwnj;mobilenet_v2/&zwnj;classification/4
[TF2] Imagenet (ILSVRC-2012-CLS) classification with MobileNet V2.

<!-- dataset: ImageNet (ILSVRC-2012-CLS) -->
<!-- asset-path: legacy -->
<!-- fine-tunable: true -->
<!-- format: saved_model_2 -->
<!-- module-type: image-classification -->
<!-- network-architecture: MobileNet V2 -->




## TF2 SavedModel

This is a SavedModel in TensorFlow 2 format.
Using it requires TensorFlow 2 (or 1.15) and TensorFlow Hub 0.5.0 or newer.

## Overview

MobileNet V2 is a family of neural network architectures for efficient
on-device image classification and related tasks, originally published by

  * Mark Sandler, Andrew Howard, Menglong Zhu, Andrey Zhmoginov,
    Liang-Chieh Chen: ["Inverted Residuals and Linear Bottlenecks:
    Mobile Networks for Classification, Detection and
    Segmentation"](https://arxiv.org/abs/1801.04381), 2018.

Mobilenets come in various sizes controlled by a multiplier for the
depth (number of features) in the convolutional layers. They can also be
trained for various sizes of input images to control inference speed.

This TF-Hub module uses the TF-Slim implementation of
`mobilenet_v2`
with a depth multiplier of 1.0 and an input size of
224x224 pixels.


The module contains a trained instance of the network, packaged to do the
[image classification](https://www.tensorflow.org/hub/common_signatures/images#classification)
that the network was trained on. If you merely want to transform images into
feature vectors, use module
[`google/tf2-preview/mobilenet_v2/feature_vector/4`](https://tfhub.dev/google/tf2-preview/mobilenet_v2/feature_vector/4)
instead, and save the space occupied by the classification layer.


## Training

The checkpoint exported into this module was `mobilenet_v2_1.0_224/mobilenet_v2_1.0_224.ckpt` downloaded
from
[MobileNet V2 pre-trained models](https://github.com/tensorflow/models/blob/master/research/slim/nets/mobilenet/README.md).
Its weights were originally obtained by training on the ILSVRC-2012-CLS
dataset for image classification ("Imagenet").

## Usage

This module can be used with the `hub.KerasLayer` as follows.
It *cannot* be used with the `hub.Module` API for TensorFlow 1.

```python
m = tf.keras.Sequential([
    hub.KerasLayer("https://tfhub.dev/google/tf2-preview/mobilenet_v2/classification/4", output_shape=[1001])
])
m.build([None, 224, 224, 3])  # Batch input shape.
```

The output is a batch of logits vectors. The indices into the logits
are the `num_classes` = 1001 classes of the classification from
the original training (see above). The mapping from indices to class labels
can be found in the file at [download.tensorflow.org/data/ImageNetLabels.txt](https://storage.googleapis.com/download.tensorflow.org/data/ImageNetLabels.txt).

The input `images` are expected to have color values in the range [0,1],
following the
[common image input](https://www.tensorflow.org/hub/common_signatures/images#input)
conventions.
For this module, the size of the input images is fixed to
`height` x `width` = 224 x 224 pixels.


## Fine-tuning

In principle, consumers of this module can
[fine-tune](https://www.tensorflow.org/hub/tf2_saved_model#fine-tuning) it
by passing `trainable=True` to `hub.KerasLayer`.
(Calling it while trainable automatically updates the moving averages of
batch normalization.)

However, fine-tuning through a large classification might be prone to overfit.


## Changelog

#### Version 1

  * Initial release.

#### Version 2

  * Fixed missing default `trainable=False`.
  * Fixed broken regularization_losses.

#### Version 3

  * Provides proper names for variables, fixing crash in `Model.save()`
    ([GitHub issue #287](https://github.com/tensorflow/hub/issues/287)).

#### Version 4

  * Adds back missing update ops for batch norm that were lost in version 3
    ([GitHub issue #304](https://github.com/tensorflow/hub/issues/304)).

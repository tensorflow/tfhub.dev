# Module vasudevgupta7/wav2vec2/1

Pre-trained speech model (without any head) from Facebook for Automatic Speech Recognition

<!-- asset-path:  https://storage.googleapis.com/wav2vec2/saved-model.tar.gz -->
<!-- task: audio-stt -->
<!-- network-architecture: wav2vec2 -->
<!-- format: saved_model_2 -->
<!-- fine-tunable: true -->
<!-- license: apache-2.0 -->
<!-- language: en -->
<!-- colab: https://colab.research.google.com/github/tensorflow/hub/blob/master/examples/colab/wav2vec2_saved_model_finetuning.ipynb -->

## Overview

This model is TensorFlow equivalent of PyTorch [`facebook/wav2vec2-base`](https://huggingface.co/facebook/wav2vec2-base). It was published in [1].

**How to use this model?**

Add randomly initalized LM head over the top of pre-trained model & fine-tune the whole model.

```python
import tensorflow as tf
import tensorflow_hub as hub

# For using this pre-trained model for training, pass `trainable=True` in `hub.KerasLayer`
pretrained_layer = hub.KerasLayer("https://tfhub.dev/vasudevgupta7/wav2vec2/1", trainable=True)

VOCAB_SIZE = 32

# Let's wrap all the layers into `tf.keras.Model` using TensorFlow's Functional API
inputs = tf.keras.Input(shape=(246000,))
hidden_states = pretrained_layer(inputs)
outputs = tf.keras.layers.Dense(VOCAB_SIZE)(hidden_states)
model = tf.keras.Model(inputs=inputs, outputs=outputs)

# For using this model, it's important to set `jit_compile=True` on GPUs/CPUs
# as some operations in this model (i.e. group-convolutions) are unsupported without it
@tf.function(jit_compile=True)
def forward(speech):
    return model(speech, training=True)

# Now, this model can trained like any other TensorFlow model
```

Note: This model shouldn't be directly used for inference. Language Model (LM) head should be added on the top of this model & it should be fine-tuned for downstream tasks like speech -> text. Complete fine-tuning workflow is shown in the accompanying notebook.

References
--------------
[1] [wav2vec 2.0: A Framework for Self-Supervised Learning of Speech Representations](https://arxiv.org/abs/2006.11477).

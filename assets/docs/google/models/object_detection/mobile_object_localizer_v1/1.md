# Module google/object_detection/mobile_object_localizer_v1/1

A class-agnostic mobile object detector.

<!-- module-type: image-object-detection -->
<!-- asset-path: legacy -->
<!-- network-architecture: MobileNet V2 -->
<!-- fine-tunable: false -->
<!-- format: hub -->
<!-- interactive-model-name: mobile_object_localizer -->

## Overview

### Module description

Mobile model to localize objects in an image.

### Input

Inputs are expected to be 3-channel RGB color images of size 192 x 192.

### Output

This model outputs four tensors:

*   **`num_detections`**: Total number of detections.
*   **`detection_boxes`**: Bounding box for each detection.
*   **`detection_scores`**: Confidence scores for each detection.
*   **`detection_classes`**: Object class for each detection. Note that this
    model supports only one class.
    [Labelmap](https://www.gstatic.com/aihub/tfhub/labelmaps/mobile_object_localizer_v1_labelmap.csv).

## Usage

### Try it now!

### Use SavedModel in Python

The model can be loaded in a Python script as follows:

```python
images = ...  # A batch of images with shape [batch_size, height, width, 3].
module = hub.Module("https://tfhub.dev/google/object_detection/mobile_object_localizer_v1/1")
features = module(images)  # Features with shape [batch_size, num_outputs].
```

The input `images` are expected to have color values in the range [0,1],
following the
[common image input](https://www.tensorflow.org/hub/common_signatures/images#input)
conventions. The input image size is 192x192 pixels.

Fine-tuning is not currently supported.

## Model architecture and training

### Model architecture

This model uses a MobileNet V2 backbone with a 0.75 width-multiplier, and a
SSDLite detection head.

MobileNet V2 is a family of neural network architectures for efficient on-device
image classification and related tasks, originally published by

*   Mark Sandler, Andrew Howard, Menglong Zhu, Andrey Zhmoginov, Liang-Chieh
    Chen: ["Inverted Residuals and Linear Bottlenecks: Mobile Networks for
    Classification, Detection and
    Segmentation"](https://arxiv.org/abs/1801.04381), 2018.

MobileNets come in various sizes controlled by a multiplier for the depth
(number of features) in the convolutional layers. They can also be trained for
various sizes of input images to control inference speed.

### Model training

This model was trained using:

*   [TensorFlow Object Detection API](https://github.com/tensorflow/models/tree/master/research/object_detection)
*   [Quantization-aware training](https://github.com/tensorflow/tensorflow/tree/r1.13/tensorflow/contrib/quantize)

### Additional information

*   Supports interactive model visualization.
*   Recommended threshold: 0.2

## Suitable Use, Limitations, and Fair Use Terms

### Suitable usecases

This model is **suitable** for localizing the most prominent objects in an
image.

### Unsuitable usecases

This model is **unsuitable** for standalone use in mission-critical applications
such as obstacle and human detection for autonomous driving.

### Limitations

*   This is a class-agnostic object detector. Object classification is not
    provided.
*   This model may not perform well on very small objects.

### License

This model follows [*Apache 2.0*](https://www.apache.org/licenses/LICENSE-2.0).
If you intend to use it beyond permissible usage, please consult with the model
owners ahead of time.

### Citation

When used for publication or production, please cite this model as: "Google
Mobile Object Localizer".

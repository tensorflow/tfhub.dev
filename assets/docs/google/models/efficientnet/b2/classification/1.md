# Module google/efficientnet/b2/classification/1

Imagenet (ILSVRC-2012-CLS) classification with EfficientNet-B2.

<!-- dataset: ImageNet (ILSVRC-2012-CLS) -->
<!-- asset-path: legacy -->
<!-- module-type: image-classification -->
<!-- network-architecture: EfficientNet-B2 -->
<!-- fine-tunable: true -->
<!-- format: hub -->



## Overview

EfficientNets are a family of image classification models, which achieve
state-of-the-art accuracy, yet being an order-of-magnitude smaller and faster
than previous models.

*   Mingxing Tan and Quoc V. Le:
    [EfficientNet: Rethinking Model Scaling for Convolutional Neural Networks](https://arxiv.org/abs/1905.11946),
    ICML 2019.

We develop EfficientNets based on AutoML and Compound Scaling. In particular, we
first use
[AutoML MNAS Mobile framework](https://ai.googleblog.com/2018/08/mnasnet-towards-automating-design-of.html)
to develop a mobile-size baseline network, named as `EfficientNet-B0`; Then, we
use the compound scaling method to scale up this baseline to obtain
`EfficientNet-B1` to `EfficientNet-B7`.

This TF-Hub module uses the TF-estimator based implementation of
`EfficientNet-B2`. The default signature is used to classify images. Besides,
the module contains a trained instance of the network, packaged to do the
[image classification](https://www.tensorflow.org/hub/common_signatures/images#classification)
that the network was trained on. We also offer a set of feature vectors to fit
different downstream tasks.

## Training

The weights for this module were obtained by training on the ILSVRC-2012-CLS
dataset for image classification ("Imagenet") with
[AutoAugment](https://arxiv.org/abs/1805.09501) preprocessing.

Please check out the
[official EfficientNet repository](https://github.com/tensorflow/tpu/tree/master/models/official/efficientnet)
for model training.

## Usage

This module implements the common signature for
[image classification](https://www.tensorflow.org/hub/common_signatures/images#classification).
It can be used like

```python
module = hub.Module("https://tfhub.dev/google/efficientnet/b2/classification/1")
height, width = hub.get_expected_image_size(module)
images = ...  # A batch of images with shape [batch_size, height, width, 3].
logits = module(images)  # Logits with shape [batch_size, num_classes].
```

...or using the signature name `image_classification`. The indices into logits
are the `num_classes` = 1000 classes of the classification from the original
training (see above). The mapping from indices to class labels can be found in
the file at
[download.tensorflow.org/data/ImageNetLabels.txt](https://storage.googleapis.com/download.tensorflow.org/data/ImageNetLabels.txt)
and please ignore the first background class, ie. index 0 corresponds to
"tench".

This module can also be used to compute
[image feature vectors](https://www.tensorflow.org/hub/common_signatures/images#feature-vector),
using the signature name `image_feature_vector`.

For this module, the size of the input image is flexible, but it would be best
to match the model training input, which is
`height` x `width` = 260 x 260 pixels for this model. The input
`images` are expected to have color values in the range [0,1], following the
[common image input](https://www.tensorflow.org/hub/common_signatures/images#input)
conventions.

## Fine-tuning

In principle, consumers of this module can
[fine-tune](https://www.tensorflow.org/hub/tf1_hub_module#fine-tuning) it.
However, fine-tuning through a large classification might be prone to overfit.

Fine-tuning requires importing the graph version with tag set `{"train"}` in
order to operate batch normalization in training mode.

## EfficientNet collection

See the collection of all EfficientNet models
[here](https://tfhub.dev/google/collections/efficientnet/1).

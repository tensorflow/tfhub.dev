# Module google/tf2-preview/mobilenet_v2/feature_vector/4
[TF2] Feature vectors of images with MobileNet V2 trained on ImageNet (ILSVRC-2012-CLS).

<!-- dataset: imagenet-ilsvrc-2012-cls -->
<!-- asset-path: legacy -->
<!-- fine-tunable: true -->
<!-- format: saved_model_2 -->
<!-- task: image-feature-vector -->
<!-- network-architecture: mobilenet-v2 -->


[![Open Colab notebook]](https://colab.research.google.com/github/tensorflow/hub/blob/master/examples/colab/tf2_image_retraining.ipynb)

## TF2 SavedModel

This is a SavedModel in TensorFlow 2 format.
Using it requires TensorFlow 2 (or 1.15) and TensorFlow Hub 0.5.0 or newer.

## Overview

MobileNet V2 is a family of neural network architectures for efficient
on-device image classification and related tasks, originally published by

  * Mark Sandler, Andrew Howard, Menglong Zhu, Andrey Zhmoginov,
    Liang-Chieh Chen: ["Inverted Residuals and Linear Bottlenecks:
    Mobile Networks for Classification, Detection and
    Segmentation"](https://arxiv.org/abs/1801.04381), 2018.

Mobilenets come in various sizes controlled by a multiplier for the
depth (number of features) in the convolutional layers. They can also be
trained for various sizes of input images to control inference speed.

This TF-Hub module uses the TF-Slim implementation of
`mobilenet_v2`
with a depth multiplier of 1.0 and an input size of
224x224 pixels.


The module contains a trained instance of the network, packaged to get
[feature vectors from images](https://www.tensorflow.org/hub/common_signatures/images#feature-vector).
If you want the full model including the classification it was originally
trained for, use module
[`google/tf2-preview/mobilenet_v2/classification/4`](https://tfhub.dev/google/tf2-preview/mobilenet_v2/classification/4)
instead.


## Training

The checkpoint exported into this module was `mobilenet_v2_1.0_224/mobilenet_v2_1.0_224.ckpt` downloaded
from
[MobileNet V2 pre-trained models](https://github.com/tensorflow/models/blob/master/research/slim/nets/mobilenet/README.md).
Its weights were originally obtained by training on the ILSVRC-2012-CLS
dataset for image classification ("Imagenet").

## Usage

This module can be used with the `hub.KerasLayer` as follows.
It *cannot* be used with the `hub.Module` API for TensorFlow 1.

```python
m = tf.keras.Sequential([
    hub.KerasLayer("https://tfhub.dev/google/tf2-preview/mobilenet_v2/feature_vector/4", output_shape=[1280],
                   trainable=False),  # Can be True, see below.
    tf.keras.layers.Dense(num_classes, activation='softmax')
])
m.build([None, 224, 224, 3])  # Batch input shape.
```

The output of the module is a batch of feature vectors. For each input image,
the feature vector has size `num_features` = 1280. The feature
vectors can then be used further, e.g., for classification as above.

The input `images` are expected to have color values in the range [0,1],
following the
[common image input](https://www.tensorflow.org/hub/common_signatures/images#input)
conventions.
For this module, the size of the input images is fixed to
`height` x `width` = 224 x 224 pixels.


## Fine-tuning

Consumers of this module can [fine-tune](https://www.tensorflow.org/hub/tf2_saved_model#fine-tuning) it
by passing `trainable=True` to `hub.KerasLayer`.
(Note that this automatically updates the moving averages of
batch normalization.)


## Changelog

#### Version 1

  * Initial release.

#### Version 2

  * Fixed missing default `trainable=False`.
  * Fixed broken regularization_losses.

#### Version 3

  * Provides proper names for variables, fixing crash in `Model.save()`
    ([GitHub issue #287](https://github.com/tensorflow/hub/issues/287)).

#### Version 4

  * Adds back missing update ops for batch norm that were lost in version 3
    ([GitHub issue #304](https://github.com/tensorflow/hub/issues/304)).

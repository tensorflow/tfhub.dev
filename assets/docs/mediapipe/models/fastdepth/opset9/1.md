# Placeholder mediapipe/fastdepth/opset9/1

Depth inference on a 3D indoor scene

<!-- module-type: image-object-detection -->
<!-- module-type: image-depth-estimation -->
<!-- fine-tunable: false -->
<!-- language: en -->
<!-- network-architecture: FastDepth -->
<!-- dataset: NYU Depth v2 -->

## Overview

Depth inference model for indoor scenes. This allows a lightweight approach for
inferring depth of objects in images. One single image is needed for inference.

It is implemented with [FastDepth](https://arxiv.org/abs/1903.03273).

### Performance

FastDepth consists of ~5MB of weights, and is well-suited for real time
inference across a variety of devices.

Since the model was trained on a dataset of indoor scenes obtained from Kinect,
the depth inference has great accuracy for objects situated not too far away
from the camera.

### Example use

In TFJS:

```
const depthmap = require('@tensorflow-models/depth-map');

const img = document.getElementById('img');
async function generateDepthMap() {
  // Load the model.
  const model = await depthmap.load();
  // The DepthMap model takes an image as input and returns a tensor containing the depth map for the image
  const output = await model.predict(img);
}
```

# Module rishit-dagli/ssd-cppe5/1

The SSD model (with MobileNet backbone) trained on the CPPE - 5 (Medical Personal Protective Equipment) dataset [1].

<!-- task: image-object-detection -->
<!-- network-architecture: ssd -->
<!-- dataset: cppe-5 -->
<!-- fine-tunable: false -->
<!-- license: apache-2.0 -->
<!-- format: saved_model_2 -->
<!-- asset-path: https://storage.googleapis.com/cppe-5/trained_models/ssd/tf_ssd.tar.gz -->

### TF2 SavedModel
This is a [SavedModel in TensorFlow 2 format](https://www.tensorflow.org/hub/tf2_saved_model). Using it requires TensorFlow 2 (or 1.15) and TensorFlow Hub 0.5.0 or newer.

### Overview
The SSD model was proposed by Liu et al. in the paper "Ssd: Single shot multibox detector" [2]. The SSD models is trained on the CPPE - 5 dataset we present in our paper "CPPE - 5: Medical Personal Protective Equipment Dataset" [1] which is a new challenging dataset with an aim to facilitate the study of subordinate categorization of medical personal protective equipments. This dataset mostly contains non-iconic images or non-canonical perspectives in their natural context. This allows models to be better at generalizing, being easily deployable to real-world scenarios and often contain other objects in an image as well.

We include the training code as well some tools for this model in our paper GitHub repository [3].

Note: In no case should this model be used to engage in any kind of high-risk activities, please [TF Hub Additional Terms of Service](https://tfhub.dev/terms#hra) for more information.

### Model Performance
Here we present the performance of the SSD model on the CPPE - 5 dataset. For evaluation, we adopt the metrics from the COCO detection evaluation criteria, including the mean Average Precision (AP) across IoU thresholds ranging from 0.50 to 0.95 at different scales.

|   Method    | AP<sup>box</sup> | AP<sub>50</sub><sup>box</sup> | AP<sub>75</sub><sup>box</sup> | AP<sub>S</sub><sup>box</sup> | AP<sub>M</sub><sup>box</sup> | AP<sub>L</sub><sup>box</sup> |
| :---------: | :--------------: | :---------------------------: | :---------------------------: | :--------------------------: | :--------------------------: | :--------------------------: |
| SSD |       29.5       |              57.0             |              24.9             |             32.1             |             23.1             |             34.6             |

### Usage
The saved model can be loaded directly:

```py
import tensorflow_hub as hub

model = hub.load("https://tfhub.dev/rishit-dagli/ssd-cppe5/1")
```

The inputs to the models should:

- have color values in the range `[0,1]`, following the [common image input](https://www.tensorflow.org/hub/common_signatures/images#input) conventions
- the expected size of the input images could be variable, but the model was trained on images of size `[640, 640]`
- the images should in the default `channels_last` format
- The shape of the input tensor would ths be `(1, -1, -1, 3)`, the first dimension represents the batch size

The model outputs are:

- `outputs['detection_anchor_indices']`: A tensor of shape `[batch_size, 100]` containing the anchor indices for each detection.
- `outputs['detection_boxes']`: A tensor of shape `[batch_size, 100, 4]` containing the boxes for each detection.
- `outputs['detection_classes']`: A tensor of shape `[batch_size, 100]` containing the class indices for each detection.
- `outputs['detection_multiclass_scores']`: A tensor of shape `[batch_size, 100, 6]` containing the class scores for each detection.
- `outputs['detection_scores']`: A tensor of shape `[batch_size, 100]` containing the scores for each detection.
- `outputs['num_detections']`: A tensor of shape `[batch_size]` containing the number of valid detections in each image.

If use be the model also outputs the `raw_detection_boxes` and `raw_detection_scores` tensors.

It can also be used within a KerasLayer:

```py
hub_layer = hub.KerasLayer("https://tfhub.dev/rishit-dagli/ssd-cppe5/1")
```

### Model Complexity
We measure the model complexity in terms of the number of parameters FLOPS and FPS. The inference speed FPS (Frames per second) for detector is measured on a machine with 1 Tesla V100 GPU.

|          Method           |      AP<sup>box</sup>      | #Params  |   FLOPs   | FPS  |
|:-------------------------:|:--------------------------:|:--------:|:---------:|:----:|
|        SSD        |            29.5            | 64.34 M  | 103.22 G  | 25.6 |

### Acknowledgements

This is joint work with Ali Mustufa Shaikh. The authors would like to thank Google for supporting this work by providing Google Cloud credits. The authors would also like to thank [Google TPU Research Cloud (TRC) program](https://sites.research.google/trc) for providing access to TPUs.

### References

[1] Dagli, Rishit, and Ali Mustufa Shaikh. ‘CPPE-5: Medical Personal Protective Equipment Dataset’. ArXiv:2112.09569 [Cs], Dec. 2021. arXiv.org, http://arxiv.org/abs/2112.09569.

[2] Liu, Wei, et al. "Ssd: Single shot multibox detector." European conference on computer vision. Springer, Cham, 2016.

[3] https://github.com/Rishit-dagli/CPPE-Dataset
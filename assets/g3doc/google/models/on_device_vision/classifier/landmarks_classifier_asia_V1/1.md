# Module google/on_device_vision/classifier/landmarks_classifier_asia_V1/1

Landmark recognition model. Tuned for Asia.

<!-- asset-path: @visionkit/fermi/classifier/landmarks_asia_V0/3 -->
<!-- module-type: image-classification -->
<!-- fine-tunable: false -->
<!-- format: hub -->
<!-- language: en -->
<!-- interactive-model-name: vision -->

## Overview

This model is trained to recognize more than 17,771 popular landmarks from Asia.
The model is mobile-friendly and can run on-device.

### Input

This model takes images as input.

*   Inputs are expected to be 3-channel RGB color images of size 321 x 321,
    scaled to [0, 1].

### Output

This model outputs to `prediction:logits`.

*   `prediction:logits`: A vector of 99543 similarity scores, corresponding to
    items in the
    [labelmap](https://www.gstatic.com/aihub/tfhub/labelmaps/landmarks_classifier_asia_V1_label_map.csv).
    Note that landmark names are in English, for example, "Fushimi Inari
    Taisha". Each landmark may appear multiple times; there are 17771 unique
    labels.

## Example use

```python

# TF1 version
import tensorflow.compat.v1 as tf
import tensorflow_hub as hub

m = hub.Module('https://tfhub.dev/google/on_device_vision/classifier/landmarks_classifier_asia_V1/1')
...

# TF2 version
import tensorflow.compat.v2 as tf
import tensorflow_hub as hub

m = hub.KerasLayer('https://tfhub.dev/google/on_device_vision/classifier/landmarks_classifier_asia_V1/1')
...
```

## Training dataset

This model was trained on
[Google Landmarks Dataset V2](https://ai.googleblog.com/2019/05/announcing-google-landmarks-v2-improved.html)
(see [paper](https://arxiv.org/abs/2004.01804))

### Suitable usecases

This model is **suitable** for:

*   Recognizing popular landmarks from conventional images

### Unsuitable usecases

This model is **unsuitable** for:

*   Predicting popularity or unpopularity of landmarks
*   Predicting the degree of cultural influence / relatendess of similar-looking
    landmarks
*   Predicting whether an image of a landmark is contained within any particular
    geopolitical region
*   Inferring the user's location

### Known limitations

*   This model assumes that the input image already contains a well-cropped
    popular landmark. If the image does not contain a landmark, the model may
    output meaningless results.
*   This model may omit some important landmarks. There may be a slight
    possibility of some cultural heritage sites being misclassified as landmarks
    from a different culture / geopolitical region.
*   The source dataset (GLDv2) distribution is mostly bounded by Wikimedia
    availability. [This paper](https://arxiv.org/abs/2004.01804) has more
    details on how the data was created.

## License

This model follows [*Apache 2.0*](https://www.apache.org/licenses/LICENSE-2.0).
If you intend to use it beyond permissible usage, please consult with the model
owners ahead of time.

## Citation

This model can be cited as:

*   Cao B, Araujo A, Sim J. Unifying Deep Local and Global Features for Image
    Search. arXiv 2020. Available: http://arxiv.org/abs/2001.05027
*   Weyand T, Araujo A, Cao B, Sim J. Google Landmarks Dataset v2-A Large-Scale
    Benchmark for Instance-Level Recognition and Retrieval. Proceedings of the
    IEEE/CVF Conference on Computer Vision and Pattern Recognition. 2020.
    Available: https://arxiv.org/abs/2004.01804

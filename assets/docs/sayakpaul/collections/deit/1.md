# Collection sayakpaul/deit/1

Collection of DeiT models.

<!-- dataset: imagenet-ilsvrc-2012-cls -->
<!-- task: image-classification -->

## Overview

This collection contains different DeiT [1] models. For more details on the training protocols,
please follow [2]. The original model weights are provided from [2]. There were ported to Keras models
(`tf.keras.Model`) and then serialized as TensorFlow SavedModels. The porting steps are available in [3].
These models were pre-trained on the ImageNet-patch16 dataset.

## About the models

Models included in this collection have two variants: (1) off-the-shelf inference for image
classification, (2) fine-tuning on downstream tasks. These models are accompanied by
Colab Notebooks for demonstration purposes. 

The table below provides a performance summary:

|    | **model_name**                   |   **top1_acc(%)** |   **top5_acc(%)** |   **orig_top1_acc(%)** |   **orig_top5_acc(%)** |
|---:|:---------------------------------|--------------:|--------------:|-------------------:|-------------------:|
|  0 | deit_tiny_patch16_224            |        72.136 |        91.128 |               72.2 |               91.1 |
|  1 | deit_tiny_distilled_patch16_224  |        74.522 |        91.896 |               74.5 |               91.9 |
|  2 | deit_small_patch16_224           |        79.828 |        94.954 |               79.9 |               95   |
|  3 | deit_small_distilled_patch16_224 |        81.172 |        95.414 |               81.2 |               95.4 |
|  4 | deit_base_patch16_224            |        81.798 |        95.592 |               81.8 |               95.6 |
|  5 | deit_base_patch16_384            |        82.894 |        96.234 |               82.9 |               96.2 |
|  6 | deit_base_distilled_patch16_224  |        83.326 |        96.496 |               83.4 |               96.5 |
|  7 | deit_base_distilled_patch16_384  |        85.238 |        97.172 |               85.2 |               97.2 |

Note that the top-1 and top-5 accuracies are reported on the ImageNet-1k validation set. 
[This directory](https://github.com/sayakpaul/deit-tf/tree/main/i1k_eval) provides details
on how these numbers were generated.

### Image classifiers

* [deit_tiny_patch16_224](https://tfhub.dev/sayakpaul/deit_tiny_patch16_224/1)
* [deit_tiny_distilled_patch16_224](https://tfhub.dev/sayakpaul/deit_tiny_distilled_patch16_224/1)
* [deit_small_patch16_224](https://tfhub.dev/sayakpaul/deit_small_patch16_224/1)
* [deit_small_distilled_patch16_224](https://tfhub.dev/sayakpaul/deit_small_distilled_patch16_224/1)
* [deit_base_patch16_224](https://tfhub.dev/sayakpaul/deit_base_patch16_224/1)
* [deit_base_distilled_patch16_224](https://tfhub.dev/sayakpaul/deit_base_distilled_patch16_224/1)
* [deit_base_patch16_384](https://tfhub.dev/sayakpaul/deit_base_patch16_384/1)
* [deit_base_distilled_patch16_384](https://tfhub.dev/sayakpaul/deit_base_distilled_patch16_384/1)


### Feature extractors

* [deit_tiny_patch16_224_fe](https://tfhub.dev/sayakpaul/deit_tiny_patch16_224_fe/1)
* [deit_tiny_distilled_patch16_224_fe](https://tfhub.dev/sayakpaul/deit_tiny_distilled_patch16_224_fe/1)
* [deit_small_patch16_224_fe]((https://tfhub.dev/sayakpaul/deit_small_patch16_224_fe/1))
* [deit_small_distilled_patch16_224_fe](https://tfhub.dev/sayakpaul/deit_small_distilled_patch16_224_fe/1)
* [deit_base_patch16_224_fe](https://tfhub.dev/sayakpaul/deit_base_patch16_224_fe/1)
* [deit_base_distilled_patch16_224_fe](https://tfhub.dev/sayakpaul/deit_base_distilled_patch16_224_fe/1)
* [deit_base_patch16_384_fe](https://tfhub.dev/sayakpaul/deit_base_patch16_384_fe/1)
* [deit_base_distilled_patch16_384_fe](https://tfhub.dev/sayakpaul/deit_base_distilled_patch16_384_fe/1)

## Notes

All the models output attention weights (i.e., softmaxed scores) from each of the transformer blocks.
The [classification Colab Notebook](https://colab.research.google.com/github/sayakpaul/deit-tf/blob/main/notebooks/classification.ipynb) shows
how to fetch the attention weights and generate an attention map for a given prediction image. 

![](https://i.imgur.com/UZANtn7.png)

## References

[1] [Training data-efficient image transformers & distillation through attention](https://arxiv.org/abs/2012.12877)

[2] [DeiT GitHub](https://github.com/facebookresearch/deit)

[3] [DeiT-TF GitHub](https://github.com/sayakpaul/deit-tf)

## Acknowledgements

* [Aritra Roy Gosthipaty](https://github.com/ariG23498)
* [ML-GDE program](https://developers.google.com/programs/experts/)

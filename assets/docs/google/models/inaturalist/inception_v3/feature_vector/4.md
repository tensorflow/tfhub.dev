# Module google/&zwnj;inaturalist/&zwnj;inception_v3/&zwnj;feature_vector/4
Feature vectors of images with Inception V3 trained on the iNaturalist (iNat) 2017 dataset.

<!-- dataset: iNaturalist (iNat) 2017 -->
<!-- asset-path: legacy -->
<!-- fine-tunable: true -->
<!-- format: saved_model_2 -->
<!-- module-type: image-feature-vector -->
<!-- network-architecture: Inception V3 -->


## TF2 SavedModel

This is a [SavedModel in TensorFlow 2
format](https://www.tensorflow.org/hub/tf2_saved_model).
Using it requires TensorFlow 2 (or 1.15) and TensorFlow Hub 0.5.0 or newer.

## Overview

This model uses the Inception V3 architecture, trained on the iNaturalist
dataset of plants and animals.

### Architecture

Inception V3 is a neural network architecture for image classification,
originally published by

  * Christian Szegedy, Vincent Vanhoucke, Sergey Ioffe, Jonathon Shlens,
    Zbigniew Wojna: ["Rethinking the Inception Architecture for Computer
    Vision"](https://arxiv.org/abs/1512.00567), 2015.

This TF Hub model uses the TF-Slim implementation of `inception_v3`.
The model contains a trained instance of the network, packaged to get
[feature vectors from images](https://www.tensorflow.org/hub/common_signatures/images.md#feature-vector).
The classification layer has been omitted.


### Training

The weights for this model were obtained by training on the iNaturalist
(iNat) 2017 dataset, after pre-training on ILSVRC-2012-CLS ("Imagenet").

The iNat2017 dataset consists of 579,184 training images and 95,986 validation
images from 5,089 species, taken from
[www.inaturalist.org](http://www.inaturalist.org).
Images were collected with different camera types, have varying image quality,
feature a large class imbalance, and have been verified by multiple
citizen scientists. The iNat2017 dataset was originally described in

  * Grant Van Horn, Oisin Mac Aodha, Yang Song, Yin Cui, Chen Sun,
    Alex Shepard, Hartwig Adam, Pietro Perona, Serge Belongie:
    ["The iNaturalist Species Classification and Detection
    Dataset"](https://arxiv.org/abs/1707.06642), CVPR 2018.

This model was trained for the study reported in

  * Yin Cui, Yang Song, Chen Sun, Andrew Howard, Serge Belongie:
    ["Large Scale Fine-Grained Categorization and Domain-Specific Transfer
    Learning"](https://arxiv.org/abs/1806.06193), CVPR 2018.

Training was done on a Cloud TPU, with "Inception-style" data
augmentation and preprocessing as for Imagenet, using the RMSProp optimizer
with epsilon = 1.0, momentum of 0.9, and a batch size of 32.
The network was trained from a checkpoint pretrained on ILSVRC-2012-CLS
("Imagenet"). The initial learning rate was set to 0.0045, with exponential
decay of 0.94 after every 4 epochs.


## Usage

This model can be used with the `hub.KerasLayer` as follows.
It *cannot* be used with the `hub.Module` API for TensorFlow 1.

```python
m = tf.keras.Sequential([
    hub.KerasLayer("https://tfhub.dev/google/inaturalist/inception_v3/feature_vector/4",
                   trainable=False),  # Can be True, see below.
    tf.keras.layers.Dense(num_classes, activation='softmax')
])
m.build([None, 299, 299, 3])  # Batch input shape.
```

The output is a batch of feature vectors. For each input image,
the feature vector has size `num_features` = 2048. The feature
vectors can then be used further, e.g., for classification as above.

The input `images` are expected to have color values in the range [0,1],
following the
[common image input](https://www.tensorflow.org/hub/common_signatures/images#input)
conventions.
The expected size of the input images is
`height` x `width` = 299 x 299 pixels
by default, but other input sizes are possible (within limits).


## Fine-tuning

Consumers of this model can [fine-tune](https://www.tensorflow.org/hub/tf2_saved_model#fine-tuning) it
by passing `trainable=True` to `hub.KerasLayer`.

The momentum (a.k.a. decay coefficient) of batch norm's exponential moving
averages defaults to 0.99 for this model, in order to accelerate training
on small datasets (or with huge batch sizes).
Advanced users can set another value (say, 0.997) by loading this model like

```python
hub.KerasLayer("https://tfhub.dev/google/inaturalist/inception_v3/feature_vector/4",
               trainable=True, arguments=dict(batch_norm_momentum=0.997))
```


## Changelog

#### Version 1

  * Initial release.

#### Version 3

  * Support for variable input size.
  * Fine-tuning: change default batch norm momentum to 0.99 and
    make it configurable.
  * Requires PIP package `tensorflow-hub>=0.2.0`.

#### Version 4

  * Switched to the SavedModel format of TensorFlow 2.
    The `hub.Module` class cannot load this or later versions any more.

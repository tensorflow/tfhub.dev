# Module vasudevgupta7/wav2vec2-960h/1

This model is fine-tuned on 960h of LibriSpeech dataset for Automatic Speech Recognition. For fine-tuning, base layer was initialized from pre-trained [wav2vec2](https://tfhub.dev/vasudevgupta7/wav2vec2/1)).

<!-- asset-path:  https://storage.googleapis.com/gsoc-weights/wav2vec2-960h/saved-model.tar.gz -->
<!-- task: audio-stt -->
<!-- network-architecture: wav2vec2-960h -->
<!-- format: saved_model_2 -->
<!-- fine-tunable: false -->
<!-- license: apache-2.0 -->
<!-- language: en -->
<!-- colab: https://colab.research.google.com/github/vasudevgupta7/gsoc-wav2vec2/blob/main/notebooks/librispeech_saved_model_evaluation.ipynb -->

## Overview

This model is TensorFlow equivalent of PyTorch [`facebook/wav2vec2-base-960h`](https://huggingface.co/facebook/wav2vec2-base-960h). It was published in [1].

**How to use this model?**

You can use this model directly for inference.

```python
import tensorflow as tf
import tensorflow_hub as hub

model = hub.KerasLayer("https://tfhub.dev/vasudevgupta7/wav2vec2-960h/1")
# For using this model, it's important to set `jit_compile=True` on GPUs/CPUs
# as some operations in this model (i.e. group-convolutions) are unsupported without it
model = tf.function(model, jit_compile=True)
```

References
--------------
[1] [wav2vec 2.0: A Framework for Self-Supervised Learning of Speech Representations](https://arxiv.org/abs/2006.11477).

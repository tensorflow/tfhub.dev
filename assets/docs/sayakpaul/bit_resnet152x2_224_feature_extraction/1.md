# Module sayakpaul/bit_r152x2_224_feature_extraction/1

BiT-ResNet152x2 feature extractor pretrained on ImageNet-1k.

<!-- asset-path: https://storage.googleapis.com/flowers-experimental/bit_r152x2_224_feature_extraction.tar.gz  -->
<!-- task: image-classification -->
<!-- network-architecture: resnet-152 -->
<!-- network-architecture: bit -->
<!-- format: saved_model_2 -->
<!-- fine-tunable: true -->
<!-- license: apache-2.0 -->
<!-- colab: https://colab.research.google.com/github/google-research/big_transfer/blob/master/colabs/big_transfer_tf2.ipynb -->


## Overview

This model is a BiT-ResNet152x2 [1] trained on the ImageNet-1k dataset [2]. 

## Using this model

```python
model = tf.keras.Sequential([
    hub.KerasLayer("https://tfhub.dev/sayakpaul/bit_r152x2_224_feature_extraction/1", trainable=True)
])
...
```

Inputs to the model must:

1. be four dimensional Tensors of the shape `(batch_size, height, width, num_channels)`. Note that the model expects images with  `channels_last`  property. `num_channels` must be 3. 
2. be resized to 224x224 resolution.
3. have pixel values in the range `[-1, 1]`.


## Notes and acknowledgements

* The original model weights are provided as a `.npz` file [3]. There were ported to a TensorFlow SavedModel. The porting steps are available in [4].
* Thanks to [Willi Gierke](https://ch.linkedin.com/in/willi-gierke) for helping with porting the weights. 


## References

[1] [Big Transfer (BiT): General Visual Representation Learning by Kolesnikov et al.](https://arxiv.org/abs/1912.11370)  

[2] [ImageNet-1k](https://www.image-net.org/challenges/LSVRC/2012/index.php)  

[3] [BiT GitHub](https://github.com/google-research/big_transfer)

[4] [Colab Notebook for assembling BiT models in TensorFlow](https://colab.research.google.com/github/sayakpaul/BiT-jax2tf/blob/main/convert_jax_weights_tf.ipynb)
# Lite iree/mobilenet_v2_100_224/uint8/1

A deployment format of iree/mobilenet_v2_100_224/uint8

<!-- parent-model: iree/mobilenet_v2_100_224/uint8 -->
<!-- asset-path: https://storage.googleapis.com/tfhub-lite-models/iree/lite-model/mobilenet_v2_100_224/uint8/1.tflite -->

## Overview

Model is in TFLite format for `uint8` inference, using quantization-aware
training. Achieves 72.6% on Imagenet.

### Input

Input buffer of size `[batch, height, width, channels]` where `batch = 1`,
`height = 224`, `width = 224`, `channels = 3` i.e. `[1, 224, 224, 3]` in uint8.
Values should be between `[0, 255]`.

### Output

Probability, a `uint8` array of size `[1][NUM_CLASS]`, where `NUM_CLASS = 1001` is
the number of classes.
